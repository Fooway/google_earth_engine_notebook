{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "# Math Stuff\n",
    "import ee, scipy.misc, random, os\n",
    "import numpy as np\n",
    "from threading import Thread\n",
    "\n",
    "# GEE stuff\n",
    "from gee_library import *\n",
    "ee.Initialize()\n",
    "\n",
    "# debug stuff\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def tile_at(center_long_lat, meters, pixels, bands):\n",
    "    \"\"\" Returns a (pixels, pixels, len(bands)) dimention numpy array of a \n",
    "    meters by meters section of earth centered at center_long_lat.\"\"\"\n",
    "    # Calculate resolution\n",
    "    resolution = meters/pixels\n",
    "    \n",
    "    # Get GPS box\n",
    "    tile_bounds = square_centered_at(\n",
    "        point = center_long_lat,\n",
    "        half_distance = meters\n",
    "    )\n",
    "    \n",
    "    # load map\n",
    "    monterey_collection = ee.ImageCollection('USDA/NAIP/DOQQ')\\\n",
    "        .filterBounds(tile_bounds)\n",
    "#         .filter(ee.Filter.date('2016-01-01', '2017-01-01'))\n",
    "        \n",
    "    # request imagery\n",
    "    tiles = img_at_region(monterey_collection, resolution, bands, tile_bounds)\n",
    "    # resize img to requested size\n",
    "    np_band_array = [scipy.misc.imresize(tiles[b], (pixels, pixels)) for b in bands]\n",
    "    # and stack the images in a matrix\n",
    "    return np.dstack(np_band_array)\n",
    "\n",
    "\n",
    "def random_tile_within(coords, meters, pixels, bands):\n",
    "    \"\"\" Chooses a random tile within the bounds of the coords.\n",
    "    This function finds a random coordinate within the bounds defined by\n",
    "    coords, then calls `tileat()` to grab that tile.\n",
    "    \n",
    "    `coords`: ((longmin, latmin),(longmax, latmax))\n",
    "    \n",
    "    Hits the server twice :/\"\"\"\n",
    "    \n",
    "    ((longmin, latmin),(longmax, latmax)) = coords\n",
    "    \n",
    "    # get random coords\n",
    "    longitude = random.uniform(longmin, longmax)\n",
    "    latitude = random.uniform(latmin, latmax)\n",
    "    \n",
    "    return tile_at((longitude, latitude), meters, pixels, bands)\n",
    "\n",
    "def save_random_tile_at(coords, meters, pixels, bands, file_name):\n",
    "    img = random_tile_within(coords, meters, pixels, bands)\n",
    "    scipy.misc.toimage(img, cmin=0.0, cmax=-1).save(file_name)\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from threading import Thread\n",
    "\n",
    "\n",
    "# Define the bounds of each geographical area\n",
    "# Cities\n",
    "chicago = ((-87.769242, 41.663568), (-87.631913, 41.993581))\n",
    "newyork = ((-73.995267, 40.596924), (-73.905278, 40.693623))\n",
    "atlanta = ((-84.409626, 33.721386), (-84.356754, 33.774483))\n",
    "sanfransisco = ((-122.448245, 37.740577), (-122.381984, 37.801367))\n",
    "# Farmland\n",
    "kansas = ((-99.647878, 38.457433), (-98.840109, 39.464683))\n",
    "montana = ((-108.323227, 46.422764), (-106.332494, 47.224012))\n",
    "georgia = ((-82.783325, 31.581322), (-82.492991, 31.813600))\n",
    "# Mountains\n",
    "sierranevadas = ((-122.533712, 43.170967), (-122.302144, 44.679019))\n",
    "cascades = ((-121.640730, 47.486787), (-120.682082, 48.886281))\n",
    "rockies = ((-106.577972, 38.700841), (-105.828700, 39.798840))\n",
    "\n",
    "training_cities = [sanfransisco, atlanta, newyork]\n",
    "test_city = [chicago]\n",
    "training_mountains = [sierranevadas, rockies]\n",
    "test_mountains=[cascades]\n",
    "training_farms=[kansas, montana]\n",
    "test_farms=[georgia]\n",
    "\n",
    "\n",
    "# Define where we will save the data\n",
    "DATA_DIR=\"./ch3_data\"\n",
    "TRAIN_IMG_DIR=os.path.join(DATA_DIR, \"train_imgs\")\n",
    "TRAIN_IMG_LABELS=os.path.join(DATA_DIR, \"train.txt\")\n",
    "TEST_IMG_DIR=os.path.join(DATA_DIR, \"test_imgs\")\n",
    "TEST_IMG_LABELS=os.path.join(DATA_DIR, \"test.txt\")\n",
    "\n",
    "# make directories if they don't exist\n",
    "for d in [DATA_DIR, TRAIN_IMG_DIR, TEST_IMG_DIR]:\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)\n",
    "\n",
    "\n",
    "def download_data(gps_bound_list, number_of_examples, directory, delay=2.5):\n",
    "    \"\"\" Downloads random tiles from a list of regions to `directory`.\n",
    "    Spawns a thread for each image with a delay of `delay` seconds\n",
    "    between thread spawns.\n",
    "    \n",
    "    Since each tile hits the server twice, and Google limits api requests\n",
    "    to 3 per second, any value less than 1.5 will likely result in server\n",
    "    errors.\"\"\"\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    for i in range(number_of_examples):\n",
    "        if i%10 == 0:\n",
    "            print i\n",
    "        t = Thread(target=save_random_tile_at,\n",
    "                   args=(random.choice(gps_bound_list),\n",
    "                         100,\n",
    "                         50,\n",
    "                         ['R', 'G', 'B'],\n",
    "                         os.path.join(directory, str(i)+'.png')))\n",
    "        t.start()\n",
    "        time.sleep(delay)\n",
    "    \n",
    "\n",
    "# #\n",
    "# # Download training data\n",
    "# #\n",
    "# number_per_training_class = 1000\n",
    "# print 'Grabbing training farms...'\n",
    "# download_data(training_farms, number_per_training_class, os.path.join(TRAIN_IMG_DIR,'farms'))\n",
    "# print 'Grabbing training cities...'\n",
    "# download_data(training_cities, number_per_training_class, os.path.join(TRAIN_IMG_DIR,'cities'))\n",
    "# print 'Grabbing training mountains...'\n",
    "# download_data(training_mountains, number_per_training_class, os.path.join(TRAIN_IMG_DIR,'mountains'))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Populate label files as comma-separated values (CSV)\n",
    "#\n",
    "\n",
    "\n",
    "with open(TRAIN_IMG_LABELS, \"w\") as myfile:\n",
    "    klass = 0\n",
    "    path = os.path.join(TRAIN_IMG_DIR,'farms')\n",
    "    for f in os.listdir(path):\n",
    "        filename = os.path.join(path, f)\n",
    "        myfile.write(filename + \",\" + str(klass) + \"\\n\")\n",
    "        \n",
    "        \n",
    "    klass = 1\n",
    "    path = os.path.join(TRAIN_IMG_DIR,'cities')\n",
    "    for f in os.listdir(path):\n",
    "        filename = os.path.join(path, f)\n",
    "        myfile.write(filename + \",\" + str(klass) + \"\\n\")\n",
    "        \n",
    "    klass = 2\n",
    "    path = os.path.join(TRAIN_IMG_DIR,'mountains')\n",
    "    for f in os.listdir(path):\n",
    "        filename = os.path.join(path, f)\n",
    "        myfile.write(filename + \",\" + str(klass) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#\n",
    "# Create Data Reader\n",
    "#\n",
    "\n",
    "# Create a string-producer tensor to actually input the filename into the system\n",
    "filename_queue = tf.train.string_input_producer([TRAIN_IMG_LABELS])\n",
    "\n",
    "# Connect it to a line-reader tensor\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "# Connect that raw line-reader to a csv decoder\n",
    "filename, labels = tf.decode_csv(value, record_defaults=[[\"error_filename\"], [\"error_label\"]])\n",
    "\n",
    "# Since the CSV has filenames in it, direct those filenames to another filereader (this time reads\n",
    "# the whole file since they're png files)\n",
    "file_contents = tf.read_file(filename)\n",
    "\n",
    "# connect that file reader to a png decoder\n",
    "png_data = tf.image.decode_png(file_contents, channels=3)\n",
    "png_data_resized = tf.image.resize_images(png_data, (50, 50)) # Because we need to define an explicit size\n",
    "\n",
    "# Since pngs are 8-bit integers, let's convert them to floats for the NN\n",
    "features = tf.cast(png_data_resized, tf.float32)\n",
    "\n",
    "# Now `features` is an image queue, and `label` is a label queue!\n",
    "\n",
    "# Once you start training, don't forget to start up the queue!\n",
    "# coord = tf.train.Coordinator()\n",
    "# threads = tf.train.start_queue_runners(coord=coord)\n",
    "# https://www.tensorflow.org/programmers_guide/reading_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Model\n",
    "#\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 50*50*3])\n",
    "y_ = tf.placeholder(tf.float32, [None])\n",
    "\n",
    "\n",
    "\n",
    "# Ensure our images are the correct shape\n",
    "input_layer = tf.reshape(x, [-1, 50, 50, 3])\n",
    "\n",
    "\n",
    "#\n",
    "# Convolutions\n",
    "#\n",
    "\n",
    "# Convolutional Layer #1\n",
    "conv1 = tf.layers.conv2d(\n",
    "    inputs=input_layer,\n",
    "    filters=32,\n",
    "    kernel_size=[3, 3],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "\n",
    "# Pooling Layer #1\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "# Convolutional Layer #2 and Pooling Layer #2\n",
    "conv2 = tf.layers.conv2d(\n",
    "    inputs=pool1,\n",
    "    filters=64,\n",
    "    kernel_size=[3, 3],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "# Convolutional Layer #3 (no pooling)\n",
    "conv3 = tf.layers.conv2d(\n",
    "    inputs=pool1,\n",
    "    filters=64,\n",
    "    kernel_size=[3, 3],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Fully Connected\n",
    "#\n",
    "\n",
    "\n",
    "# Dense Layer\n",
    "conv3_flat = tf.reshape(conv3, [-1, 9 * 9 * 64])\n",
    "dense = tf.layers.dense(inputs=conv3_flat, units=1024, activation=tf.nn.relu)\n",
    "dropout = tf.layers.dropout(\n",
    "    inputs=dense,\n",
    "    rate=0.4,\n",
    "    training= True)\n",
    "\n",
    "# Logits Layer\n",
    "logits = tf.layers.dense(inputs=dropout, units=3)\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Loss\n",
    "#\n",
    "\n",
    "# Turn our numerical labels into one-hot arrays\n",
    "onehot_labels = tf.one_hot(indices=tf.cast(y_, tf.int32), depth=3)\n",
    "\n",
    "loss = None\n",
    "train_op = None\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(\n",
    "    onehot_labels=onehot_labels, # ground truth\n",
    "    logits=logits) # network output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Train\n",
    "# \n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.contrib.layers.optimize_loss(\n",
    "    loss=loss,\n",
    "    global_step=tf.contrib.framework.get_global_step(),\n",
    "    learning_rate=0.001,\n",
    "    optimizer=\"SGD\")\n",
    "\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Initialize tensorflow\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "# And run 20k iterations\n",
    "for i in range(20000):\n",
    "    print i\n",
    "    # make batch\n",
    "    example_batch, label_batch = tf.train.shuffle_batch(\n",
    "                [features, labels],\n",
    "                batch_size=10,\n",
    "                capacity=500, # max we will queue\n",
    "                min_after_dequeue=100) # size of pool to sample from\n",
    "    \n",
    "    # Debug output\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:sess.run(example_batch),\n",
    "                                                 y_: sess.run(label_batch)})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "        \n",
    "    # run an iteration\n",
    "    optimizer.run(feed_dict={x:sess.run(example_batch),\n",
    "                             y_: sess.run(label_batch)})\n",
    "\n",
    "    \n",
    "# Final accuracy\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# initialize interactive session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# inputs ('None' refers to batch size)\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "\n",
    "#\n",
    "# Helper functions for creating layers and initializing variables\n",
    "#\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############\n",
    "# First Layer\n",
    "#\n",
    "\n",
    "# make variables (5x5 kernel, 1 channel img, 32 filters)\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "# reshape input (-1 is batch size)\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "\n",
    "# conv and pooling\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "\n",
    "\n",
    "##############\n",
    "# Second Layer\n",
    "#\n",
    "\n",
    "# make variables (32 channels coming in, 64 going out)\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "# no reshaping of input necessary. input h_pool1 should have shape ...\n",
    "\n",
    "# conv and pooling\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######################\n",
    "# Fully Connected Layer\n",
    "#\n",
    "\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "# flatten convolution layer for FC operations\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "\n",
    "###########\n",
    "# Dropout\n",
    "#\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32) # allows us to turn DO on and off during training and testing\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "\n",
    "################\n",
    "# Readout layer\n",
    "#\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.16\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c1771ab45368>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# run an interation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtrain_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   1586\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m     \"\"\"\n\u001b[0;32m-> 1588\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3830\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3831\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3832\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#\n",
    "# Traning and testing\n",
    "#\n",
    "\n",
    "# loss\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "\n",
    "# optimizer\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Initialize tensorflow\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# And run 20k iterations\n",
    "for i in range(20000):\n",
    "    \n",
    "    # make batch\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    \n",
    "    # Debug output\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "        \n",
    "    # run an interation\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "    \n",
    "# Final accuracy\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Mnist version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9191\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#\n",
    "# Define Network\n",
    "#\n",
    "\n",
    "# A placeholder is a thing that *we* will be filling\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "# A variable is a thing that we can fill and the network can also change\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# prediction\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "# ground truth\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# loss function\n",
    "# cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y)\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "\n",
    "#\n",
    "# Train\n",
    "#\n",
    "\n",
    "# Define optimizer\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "# initialize session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# initialize variables\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# train 1000 steps\n",
    "for _ in range(1000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "    \n",
    "#\n",
    "# Evaluate\n",
    "#\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
