{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "# Math Stuff\n",
    "import ee, scipy.misc, random, os\n",
    "import numpy as np\n",
    "from threading import Thread\n",
    "\n",
    "# GEE stuff\n",
    "from gee_library import *\n",
    "ee.Initialize()\n",
    "\n",
    "# debug stuff\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def tile_at(center_long_lat, meters, pixels, bands):\n",
    "    \"\"\" Returns a (pixels, pixels, len(bands)) dimention numpy array of a \n",
    "    meters by meters section of earth centered at center_long_lat.\"\"\"\n",
    "    # Calculate resolution\n",
    "    resolution = meters/pixels\n",
    "    \n",
    "    # Get GPS box\n",
    "    tile_bounds = square_centered_at(\n",
    "        point = center_long_lat,\n",
    "        half_distance = meters\n",
    "    )\n",
    "    \n",
    "    # load map\n",
    "    monterey_collection = ee.ImageCollection('USDA/NAIP/DOQQ')\\\n",
    "        .filterBounds(tile_bounds)\n",
    "#         .filter(ee.Filter.date('2016-01-01', '2017-01-01'))\n",
    "        \n",
    "    # request imagery\n",
    "    tiles = img_at_region(monterey_collection, resolution, bands, tile_bounds)\n",
    "    # resize img to requested size\n",
    "    np_band_array = [scipy.misc.imresize(tiles[b], (pixels, pixels)) for b in bands]\n",
    "    # and stack the images in a matrix\n",
    "    return np.dstack(np_band_array)\n",
    "\n",
    "\n",
    "def random_tile_within(coords, meters, pixels, bands):\n",
    "    \"\"\" Chooses a random tile within the bounds of the coords.\n",
    "    This function finds a random coordinate within the bounds defined by\n",
    "    coords, then calls `tileat()` to grab that tile.\n",
    "    \n",
    "    `coords`: ((longmin, latmin),(longmax, latmax))\n",
    "    \n",
    "    Hits the server twice :/\"\"\"\n",
    "    \n",
    "    ((longmin, latmin),(longmax, latmax)) = coords\n",
    "    \n",
    "    # get random coords\n",
    "    longitude = random.uniform(longmin, longmax)\n",
    "    latitude = random.uniform(latmin, latmax)\n",
    "    \n",
    "    return tile_at((longitude, latitude), meters, pixels, bands)\n",
    "\n",
    "def save_random_tile_at(coords, meters, pixels, bands, file_name):\n",
    "    try:\n",
    "        img = random_tile_within(coords, meters, pixels, bands)\n",
    "        scipy.misc.toimage(img, cmin=0.0, cmax=-1).save(file_name)\n",
    "    except ServerError as e:\n",
    "        print e, file_name\n",
    "    except Exception as e:\n",
    "        print e, file_name, coords\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbing training farms...\n",
      "Grabbing training cities...\n",
      "Grabbing training mountains...\n",
      "Grabbing testing farms...\n",
      "0\n",
      "Status code 429 ./ch3_data_try_two/test_imgs/farms/2.png\n",
      "Status code 429 ./ch3_data_try_two/test_imgs/farms/6.png\n",
      "Status code 429 ./ch3_data_try_two/test_imgs/farms/7.png\n",
      "EOF occurred in violation of protocol (_ssl.c:661) ./ch3_data_try_two/test_imgs/farms/3.png ((-121.789047, 38.223409), (-121.575699, 38.473852))\n",
      "Status code 429 ./ch3_data_try_two/test_imgs/farms/12.png\n",
      "Status code 429 ./ch3_data_try_two/test_imgs/farms/17.png\n",
      "Status code 429 ./ch3_data_try_two/test_imgs/farms/22.png\n",
      "Status code 429 ./ch3_data_try_two/test_imgs/farms/25.png\n",
      "Status code 429 ./ch3_data_try_two/test_imgs/farms/28.png\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from threading import Thread\n",
    "\n",
    "\n",
    "# Define the bounds of each geographical area\n",
    "# Cities\n",
    "brooklyn= ((-73.965471, 40.614974), (-73.920207, 40.693991))\n",
    "longisland= ((-73.918610, 40.713007), (-73.840551, 40.775980))\n",
    "queens= ((-73.821792, 40.749724), (-73.760813, 40.780303))\n",
    "# chicago1= ((-87.769646, 41.839960), (-87.646641, 41.967390))\n",
    "# chicago2= ((-87.799684, 41.667181), (-87.603884, 41.843095))\n",
    "sf1= ((-122.453085, 37.719024), (-122.394265, 37.789567))\n",
    "sanjose= ((-122.033408, 37.243222), (-121.832452, 37.414198))\n",
    "sandiego= ((-117.144966, 32.743224), (-117.098079, 32.761772))\n",
    "sandiego2= ((-117.098079, 32.690284), (-117.021168, 32.743224))\n",
    "denver= ((-105.127158, 39.569603), (-104.890206, 39.825191))\n",
    "neworleans= ((-90.229627, 29.967342), (-90.034561, 30.016651))\n",
    "baltimore= ((-76.651899, 39.287861), (-76.609940, 39.311176))\n",
    "# Farmland\n",
    "kentucky= ((-84.479444, 38.110622), (-84.335569, 38.258371))\n",
    "kansas= ((-97.533941, 38.105647), (-96.815051, 38.366043))\n",
    "montana= ((-108.994821, 45.875502), (-108.770538, 46.105918))\n",
    "california= ((-121.789047, 38.223409), (-121.575699, 38.473852))\n",
    "virginia= ((-76.838359, 36.483186), (-76.609497, 36.684365))\n",
    "# Mountains\n",
    "cascades = ((-121.575448, 48.224966), (-120.395554, 48.955637))\n",
    "bc = ((-126.871931, 50.727633), (-122.548457, 51.421085))\n",
    "sierranevadas = ((-120.479266, 38.206113), (-120.198767, 39.346931))\n",
    "yellowstone = ((-110.042831, 43.716602), (-109.379713, 44.437358))\n",
    "rockies = ((-106.790375, 38.610576), (-106.352140, 39.315902))\n",
    "rockies2 = ((-107.872873, 37.627164), (-106.433726, 38.047526))\n",
    "jasper = ((-118.961940, 51.490493), (-116.910005, 52.873976))\n",
    "yosemite = ((-119.956063, 37.535445), (-119.282902, 38.176927))\n",
    "\n",
    "\n",
    "training_cities = [brooklyn, longisland, queens, sf1, sanjose, sandiego, sandiego2]\n",
    "test_cities = [baltimore, neworleans]\n",
    "\n",
    "training_mountains = [cascades, bc, sierranevadas, yellowstone, rockies, rockies2]\n",
    "test_mountains=[jasper, yosemite]\n",
    "\n",
    "training_farms=[montana, kansas, kentucky]\n",
    "test_farms=[virginia, california]\n",
    "\n",
    "\n",
    "# Define where we will save the data\n",
    "DATA_DIR=\"./ch3_data_try_two\"\n",
    "TRAIN_IMG_DIR=os.path.join(DATA_DIR, \"train_imgs\")\n",
    "TRAIN_IMG_LABELS=os.path.join(DATA_DIR, \"train.txt\")\n",
    "TEST_IMG_DIR=os.path.join(DATA_DIR, \"test_imgs\")\n",
    "TEST_IMG_LABELS=os.path.join(DATA_DIR, \"test.txt\")\n",
    "\n",
    "# make directories if they don't exist\n",
    "for d in [DATA_DIR, TRAIN_IMG_DIR, TEST_IMG_DIR]:\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)\n",
    "\n",
    "\n",
    "def download_data(gps_bound_list, number_of_examples, directory, delay=3):\n",
    "    \"\"\" Downloads random tiles from a list of regions to `directory`.\n",
    "    Spawns a thread for each image with a delay of `delay` seconds\n",
    "    between thread spawns. \"\"\"\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    for i in range(number_of_examples):\n",
    "        if i%100 == 0:\n",
    "            print i\n",
    "        t = Thread(target=save_random_tile_at,\n",
    "                   args=(random.choice(gps_bound_list),\n",
    "                         200,\n",
    "                         50,\n",
    "                         ['R', 'G', 'B'],\n",
    "                         os.path.join(directory, str(i)+'.png')))\n",
    "        t.start()\n",
    "        time.sleep(delay)\n",
    "    \n",
    "\n",
    "#\n",
    "# Download training data\n",
    "#\n",
    "number_per_training_class = 4000\n",
    "print 'Grabbing training farms...'\n",
    "# download_data(training_farms, number_per_training_class, os.path.join(TRAIN_IMG_DIR,'farms'))\n",
    "print 'Grabbing training cities...'\n",
    "# download_data(training_cities, number_per_training_class, os.path.join(TRAIN_IMG_DIR,'cities'))\n",
    "print 'Grabbing training mountains...'\n",
    "# download_data(training_mountains, number_per_training_class, os.path.join(TRAIN_IMG_DIR,'mountains'))\n",
    "\n",
    "\n",
    "#\n",
    "# Download test data\n",
    "#\n",
    "number_per_test_class = 500\n",
    "print 'Grabbing testing farms...'\n",
    "download_data(test_farms, number_per_test_class, os.path.join(TEST_IMG_DIR,'farms'))\n",
    "print 'Grabbing testing cities...'\n",
    "download_data(test_cities, number_per_test_class, os.path.join(TEST_IMG_DIR,'cities'))\n",
    "print 'Grabbing testing mountains...'\n",
    "download_data(test_mountains, number_per_test_class, os.path.join(TEST_IMG_DIR,'mountains'))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Populate label files as comma-separated values (CSV)\n",
    "#\n",
    "\n",
    "# Training Data\n",
    "with open(TRAIN_IMG_LABELS, \"w\") as myfile:\n",
    "    klass = 0\n",
    "    path = os.path.join(TRAIN_IMG_DIR,'farms')\n",
    "    for f in os.listdir(path):\n",
    "        filename = os.path.join(path, f)\n",
    "        myfile.write(filename + \",\" + str(klass) + \"\\n\")\n",
    "            \n",
    "    klass = 1\n",
    "    path = os.path.join(TRAIN_IMG_DIR,'cities')\n",
    "    for f in os.listdir(path):\n",
    "        filename = os.path.join(path, f)\n",
    "        myfile.write(filename + \",\" + str(klass) + \"\\n\")\n",
    "        \n",
    "    klass = 2\n",
    "    path = os.path.join(TRAIN_IMG_DIR,'mountains')\n",
    "    for f in os.listdir(path):\n",
    "        filename = os.path.join(path, f)\n",
    "        myfile.write(filename + \",\" + str(klass) + \"\\n\")\n",
    "        \n",
    "\n",
    "# Test Data\n",
    "with open(TEST_IMG_LABELS, \"w\") as myfile:\n",
    "    klass = 0\n",
    "    path = os.path.join(TEST_IMG_DIR,'farms')\n",
    "    for f in os.listdir(path):\n",
    "        filename = os.path.join(path, f)\n",
    "        myfile.write(filename + \",\" + str(klass) + \"\\n\")\n",
    "            \n",
    "    klass = 1\n",
    "    path = os.path.join(TEST_IMG_DIR,'cities')\n",
    "    for f in os.listdir(path):\n",
    "        filename = os.path.join(path, f)\n",
    "        myfile.write(filename + \",\" + str(klass) + \"\\n\")\n",
    "        \n",
    "    klass = 2\n",
    "    path = os.path.join(TEST_IMG_DIR,'mountains')\n",
    "    for f in os.listdir(path):\n",
    "        filename = os.path.join(path, f)\n",
    "        myfile.write(filename + \",\" + str(klass) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#\n",
    "# Create Data Reader\n",
    "#\n",
    "\n",
    "# Create a string-producer tensor to actually input the filename into the system\n",
    "filename_queue = tf.train.string_input_producer([TRAIN_IMG_LABELS])\n",
    "\n",
    "# Connect it to a line-reader tensor\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "# Connect that raw line-reader to a csv decoder\n",
    "filename, labels = tf.decode_csv(value, record_defaults=[[\"error_filename\"], [\"error_label\"]])\n",
    "\n",
    "# Since the CSV has filenames in it, direct those filenames to another filereader (this time reads\n",
    "# the whole file since they're png files)\n",
    "file_contents = tf.read_file(filename)\n",
    "\n",
    "# connect that file reader to a png decoder\n",
    "png_data = tf.image.decode_png(file_contents, channels=3)\n",
    "png_data_resized = tf.image.resize_images(png_data, (50, 50)) # Because we need to define an explicit size\n",
    "\n",
    "# Since pngs are 8-bit integers, let's convert them to floats for the NN\n",
    "features = tf.cast(png_data_resized, tf.float32)\n",
    "\n",
    "# Now `features` is an image queue, and `label` is a label queue!\n",
    "\n",
    "# Once you start training, don't forget to start up the queue!\n",
    "# coord = tf.train.Coordinator()\n",
    "# threads = tf.train.start_queue_runners(coord=coord)\n",
    "# https://www.tensorflow.org/programmers_guide/reading_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import misc\n",
    "\n",
    "def gee_batch(data_label_file, batch_size):\n",
    "    \"\"\"Generates batches of size `batch_size`\"\"\"\n",
    "    \n",
    "    # read file\n",
    "    lines = open(data_label_file).read().splitlines()\n",
    "    \n",
    "    img_list = []\n",
    "    label_list = []\n",
    "    for i in range(batch_size):\n",
    "        png_path, label = random.choice(lines).split(',')\n",
    "        img_list.append(misc.imread(png_path).flatten())\n",
    "#         img_list.append(np.zeros(50*50*3))\n",
    "        one_hot = np.zeros(3)\n",
    "        one_hot[int(label)] = 1\n",
    "        label_list.append(one_hot)\n",
    "        \n",
    "    return np.stack(img_list, axis=0), np.stack(label_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Model\n",
    "#\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 50*50*3])\n",
    "y_ = tf.placeholder(tf.float32, [None, 3])\n",
    "training = tf.placeholder(tf.bool)\n",
    "\n",
    "\n",
    "\n",
    "# Ensure our images are the correct shape\n",
    "input_layer = tf.reshape(x, [-1, 50, 50, 3])\n",
    "\n",
    "\n",
    "#\n",
    "# Convolutions\n",
    "#\n",
    "\n",
    "# Convolutional Layer #1\n",
    "conv1 = tf.layers.conv2d(\n",
    "    inputs=input_layer,\n",
    "    filters=32,\n",
    "    kernel_size=[3, 3],\n",
    "    padding=\"valid\",\n",
    "    activation=tf.nn.relu)\n",
    "\n",
    "# Pooling Layer #1\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "# Convolutional Layer #2 and Pooling Layer #2\n",
    "conv2 = tf.layers.conv2d(\n",
    "    inputs=pool1,\n",
    "    filters=64,\n",
    "    kernel_size=[3, 3],\n",
    "    padding=\"valid\",\n",
    "    activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "# Convolutional Layer #3 (no pooling)\n",
    "conv3 = tf.layers.conv2d(\n",
    "    inputs=pool2,\n",
    "    filters=64,\n",
    "    kernel_size=[3, 3],\n",
    "    padding=\"valid\",\n",
    "    activation=tf.nn.relu)\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Fully Connected\n",
    "#\n",
    "\n",
    "\n",
    "# Dense Layer\n",
    "conv3_flat = tf.reshape(conv3, [-1, 9 * 9 * 64])\n",
    "dense = tf.layers.dense(inputs=conv3_flat, units=1024, activation=tf.nn.relu)\n",
    "dropout = tf.layers.dropout(\n",
    "    inputs=dense,\n",
    "    rate=0.4,\n",
    "    training= True)\n",
    "\n",
    "# Logits Layer\n",
    "logits = tf.layers.dense(inputs=dropout, units=3)\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Loss\n",
    "#\n",
    "\n",
    "# Turn our numerical labels into one-hot arrays\n",
    "# onehot_labels = tf.one_hot(indices=tf.cast(y_, tf.int32), depth=3)\n",
    "onehot_labels = y_\n",
    "\n",
    "loss = None\n",
    "train_op = None\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(\n",
    "    onehot_labels=onehot_labels, # ground truth\n",
    "    logits=logits) # network output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Train\n",
    "# \n",
    "\n",
    "# # optimizer\n",
    "# optimizer = tf.contrib.layers.optimize_loss(\n",
    "#     loss=loss,\n",
    "#     global_step=tf.contrib.framework.get_global_step(),\n",
    "#     learning_rate=0.001,\n",
    "#     optimizer=\"SGD\")\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Initialize tensorflow\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "# And run 20k iterations\n",
    "for i in range(1000):\n",
    "    # make batch\n",
    "    example_batch, label_batch = gee_batch(TRAIN_IMG_LABELS, 9)\n",
    "    \n",
    "    \n",
    "    # Debug output\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x : example_batch,\n",
    "                                                  y_: label_batch,\n",
    "                                                  training: False})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "        \n",
    "    # run an iteration\n",
    "    optimizer.run(feed_dict={x:example_batch,\n",
    "                             y_: label_batch,\n",
    "                             training: True})\n",
    "\n",
    "    \n",
    "# Final accuracy\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, training: False}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "\n",
    "# farm, city, mountain\n",
    "\n",
    "example_batch, label_batch = gee_batch(TEST_IMG_LABELS, 1)\n",
    "\n",
    "predictions = sess.run(logits, feed_dict={x:example_batch, y_: label_batch, training: False})\n",
    "\n",
    "answers = np.argmax(label_batch, axis=1)\n",
    "predictions_max = np.argmax(predictions, axis=1)\n",
    "\n",
    "print np.count_nonzero((answers == predictions_max)*1) / float(len(predictions_max))\n",
    "\n",
    "img = example_batch.reshape((50,50,3))\n",
    "plt.imshow(img); plt.show()\n",
    "\n",
    "print \"predictions:\", predictions\n",
    "print \"ground truth:\", label_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
