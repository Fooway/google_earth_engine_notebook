{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Supervised Learning\n",
    "\n",
    "In this chapter we will used the Earth Engine techniques from earlier chapters to train a neural network in a simple classification task. This will involve two steps. First, we will automate the download and labeling tasks. Second, we will design, train, and evaluate a neural network using TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "# Math Stuff\n",
    "import ee, scipy.misc, random, os\n",
    "import numpy as np\n",
    "\n",
    "# GEE stuff\n",
    "from gee_library import *\n",
    "ee.Initialize()\n",
    "\n",
    "# debug stuff\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Multi threading\n",
    "import time\n",
    "from threading import Thread\n",
    "\n",
    "# Machine learning\n",
    "import tensorflow as tf\n",
    "from scipy import misc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating testing and training data\n",
    "\n",
    "Neural networks require huge amounts of data to be effective; a supervised classifier will require that all that data be *labeled* as well. Since labeling that much data would be require a huge amount of work for a human to accomplish, we will automate the task.\n",
    "\n",
    "Our neural network will be trained to classify imagery as one of three classes: farmland, mountains, a city. Defining our classes this way allows us to automate the labeling process; we only have to know the gps bounds of a city and every tile we grab from that area can be labeled \"city.\"\n",
    "\n",
    "The next section will walk though a simple automated-imagery-downloader. It will save the images to your hard drive and generate a CSV file that indexes each image with its label. (The pattern of flat images with label files is common for computer vision datasets.) In this chapeter we will leave the images as flat files and feed them directly into the neural network. The next chapter will look into encapsulating them into a more efficient data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Define where we will save the data. \n",
    "#\n",
    "DATA_DIR=\"data/ch3\"\n",
    "TRAIN_IMG_DIR=os.path.join(DATA_DIR, \"train_imgs\")\n",
    "TRAIN_IMG_LABELS=os.path.join(DATA_DIR, \"train.txt\")\n",
    "TEST_IMG_DIR=os.path.join(DATA_DIR, \"test_imgs\")\n",
    "TEST_IMG_LABELS=os.path.join(DATA_DIR, \"test.txt\")\n",
    "\n",
    "\n",
    "#\n",
    "# We will define areas to grab imagery from. When selecting these areas we\n",
    "# had to be careful that they were large enough that taking random selections from\n",
    "# them wouldn't result in repeated images. \n",
    "#\n",
    "\n",
    "# Cities\n",
    "brooklyn= ((-73.965471, 40.614974), (-73.920207, 40.693991))\n",
    "longisland= ((-73.918610, 40.713007), (-73.840551, 40.775980))\n",
    "queens= ((-73.821792, 40.749724), (-73.760813, 40.780303))\n",
    "sf1= ((-122.453085, 37.719024), (-122.394265, 37.789567))\n",
    "sanjose= ((-122.033408, 37.243222), (-121.832452, 37.414198))\n",
    "sandiego= ((-117.144966, 32.743224), (-117.098079, 32.761772))\n",
    "sandiego2= ((-117.098079, 32.690284), (-117.021168, 32.743224))\n",
    "denver= ((-105.127158, 39.569603), (-104.890206, 39.825191))\n",
    "neworleans= ((-90.229627, 29.967342), (-90.034561, 30.016651))\n",
    "baltimore= ((-76.651899, 39.287861), (-76.609940, 39.311176))\n",
    "# Farmland\n",
    "kentucky= ((-84.479444, 38.110622), (-84.335569, 38.258371))\n",
    "kansas= ((-97.533941, 38.105647), (-96.815051, 38.366043))\n",
    "montana= ((-108.994821, 45.875502), (-108.770538, 46.105918))\n",
    "california= ((-121.789047, 38.223409), (-121.575699, 38.473852))\n",
    "virginia= ((-76.838359, 36.483186), (-76.609497, 36.684365))\n",
    "# Mountains\n",
    "cascades = ((-121.575448, 48.224966), (-120.395554, 48.955637))\n",
    "# bc = ((-126.871931, 50.727633), (-122.548457, 51.421085))\n",
    "sierranevadas = ((-120.479266, 38.206113), (-120.198767, 39.346931))\n",
    "yellowstone = ((-110.042831, 43.716602), (-109.379713, 44.437358))\n",
    "rockies = ((-106.790375, 38.610576), (-106.352140, 39.315902))\n",
    "rockies2 = ((-107.872873, 37.627164), (-106.433726, 38.047526))\n",
    "# jasper = ((-118.961940, 51.490493), (-116.910005, 52.873976))\n",
    "yosemite = ((-119.956063, 37.535445), (-119.282902, 38.176927))\n",
    "\n",
    "#\n",
    "# Now we separate the areas into test and training sets. This separation is very important!\n",
    "# Evaluating a statistical model using the same data you trained it on can lead to overfitting\n",
    "# and poor real-world results.\n",
    "#\n",
    "# We're being extra-careful here by including completely different areas in the test and training\n",
    "# sets. Our downloader is fairly unsophisticated and simply grabs random samples from each area;\n",
    "# there is a chance that the some images might overlap. We also wanted to make sure that the\n",
    "# classifier will be able to generalize to new cities not yet seen.\n",
    "#\n",
    "\n",
    "training_cities = [brooklyn, longisland, queens, sf1, sanjose, sandiego, sandiego2]\n",
    "test_cities = [baltimore, neworleans]\n",
    "\n",
    "training_mountains = [cascades, sierranevadas, yellowstone, rockies]\n",
    "test_mountains=[yosemite, rockies2]\n",
    "\n",
    "training_farms=[montana, kansas, kentucky]\n",
    "test_farms=[virginia, california]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def download_data(gps_bound_list, number_of_examples, directory, delay=2):\n",
    "    \"\"\"\n",
    "    Downloads random tiles from a list of regions to `directory`. This function only downloads\n",
    "    the images; it does not generate the CSV file. \n",
    "    \n",
    "    The process of querying the server for a download URL and then downloading and unzipping the\n",
    "    images takes several seconds per image. We can work on multiple images at once by spawning a\n",
    "    separate thread for each image request. This function shows a simple approach to multi-threading.\n",
    "\n",
    "    Google Earth Engine limits the number of requests that an individual can make. If too many images\n",
    "    are resulting in 429 ServerErrors, try increasing the delay.\n",
    "    \n",
    "    gps_bound_list   (List): list of gps coordinates. For example:\n",
    "            [ ((-73.965, 40.614), (-73.920, 40.693)),\n",
    "              ((-105.127, 39.569), (-104.890, 39.825)) ]\n",
    "    number_of_examples(int): The number of images that will be downloaded.\n",
    "    directory      (string): Images will be saved to this directory.\n",
    "    delay             (int): The delay between requests, in seconds.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    for i in range(number_of_examples):\n",
    "        if i%100 == 0:\n",
    "            print i\n",
    "        t = Thread(target=save_random_tile_at,\n",
    "                   args=(random.choice(gps_bound_list),\n",
    "                         600,\n",
    "                         50,\n",
    "                         ['R', 'G', 'B'],\n",
    "                         os.path.join(directory, str(i)+'.png')))\n",
    "        t.start()\n",
    "        time.sleep(delay)\n",
    "\n",
    "\n",
    "def save_random_tile_at(coords, meters, pixels, bands, file_name):\n",
    "    \"\"\"\n",
    "    Saves a random (pixels x pixels) image from the region described by coords.\n",
    "    The image will be saved to disk at file_name.\n",
    "    \n",
    "    coords: Two gps points describing a rectangle in the form:\n",
    "        ((longitude_min, latitude_min),(longitude_max, latitude_max))\n",
    "    meters: Each image will depict and area measuring meters x meters \n",
    "    pixels: Each image will measure pixels x pixels\n",
    "    bands: List of requested bands. For example: ['R', 'G', 'B']\n",
    "    file_name: File path where the image should be saved at. For example \"./tmp/IMG0293.png\"\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get random location in box\n",
    "        ((longmin, latmin),(longmax, latmax)) = coords\n",
    "\n",
    "        # get random coords\n",
    "        longitude = random.uniform(longmin, longmax)\n",
    "        latitude = random.uniform(latmin, latmax)\n",
    "\n",
    "        # Calculate resolution\n",
    "        resolution = meters/pixels\n",
    "\n",
    "        # Build the GPS box Geometry object\n",
    "        tile_bounds = square_centered_at(\n",
    "            point = (longitude, latitude),\n",
    "            half_distance = meters / 2\n",
    "        )\n",
    "\n",
    "        # load image collection\n",
    "        monterey_collection = ee.ImageCollection('USDA/NAIP/DOQQ')\\\n",
    "            .filterBounds(tile_bounds)\n",
    "\n",
    "        # request imagery\n",
    "        tiles = img_at_region(monterey_collection, resolution, bands, tile_bounds)\n",
    "\n",
    "        # resize img to requested size\n",
    "        np_band_array = [scipy.misc.imresize(tiles[b], (pixels, pixels)) for b in bands]\n",
    "\n",
    "        # and stack the images in a matrix\n",
    "        img = np.dstack(np_band_array)\n",
    "        \n",
    "        # make sure the image isn't a blank image (some times this happens if you get the coordinates\n",
    "        # wrong and point to an area not covered.)\n",
    "        if np.mean(img) == 0:\n",
    "            raise Exception(\"Blank image detected.\")\n",
    "\n",
    "        # Save image to file\n",
    "        scipy.misc.toimage(img, cmin=0.0, cmax=-1).save(file_name)\n",
    "        \n",
    "    #\n",
    "    # Error Handling\n",
    "    #\n",
    "    except ServerError as e:\n",
    "        print e, file_name, coords\n",
    "    except Exception as e:\n",
    "        print e, file_name, coords\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Now we'll use all the functions and lists we made to download all of our data.\n",
    "# Keep in mind this is a long process and will take several hours. You can\n",
    "# expediate the process by reducing the number of examples (but you may get worse results.)\n",
    "#\n",
    "\n",
    "#\n",
    "# Download training data\n",
    "#\n",
    "number_per_training_class = 2000\n",
    "print 'Grabbing training farms...'\n",
    "# download_data(training_farms, number_per_training_class, os.path.join(TRAIN_IMG_DIR,'farms'))\n",
    "print 'Grabbing training cities...'\n",
    "# download_data(training_cities, number_per_training_class, os.path.join(TRAIN_IMG_DIR,'cities'))\n",
    "print 'Grabbing training mountains...'\n",
    "download_data(training_mountains, number_per_training_class, os.path.join(TRAIN_IMG_DIR,'mountains'))\n",
    "\n",
    "\n",
    "#\n",
    "# Download test data\n",
    "#\n",
    "number_per_test_class = 500\n",
    "print 'Grabbing testing farms...'\n",
    "# download_data(test_farms, number_per_test_class, os.path.join(TEST_IMG_DIR,'farms'))\n",
    "print 'Grabbing testing cities...'\n",
    "# download_data(test_cities, number_per_test_class, os.path.join(TEST_IMG_DIR,'cities'))\n",
    "print 'Grabbing testing mountains...'\n",
    "download_data(test_mountains, number_per_test_class, os.path.join(TEST_IMG_DIR,'mountains'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Populate label files as comma-separated values (CSV).\n",
    "# We could have done this step at the same time we downloaded the files, but multiple\n",
    "# threads writing to the same file can be complicated to do right. Instead, we downloaded\n",
    "# each class of image to a separate directory. Since we know the label for each image in\n",
    "# a directory, we can generate the CSV file here.\n",
    "#\n",
    "\n",
    "# Training Data\n",
    "with open(TRAIN_IMG_LABELS, \"w\") as myfile:\n",
    "    klass = 0   # 'class' is a reserved keyword in Python.\n",
    "    path = os.path.join(TRAIN_IMG_DIR,'farms')\n",
    "    for f in os.listdir(path):\n",
    "        filename = os.path.join(path, f)\n",
    "        myfile.write(filename + \",\" + str(klass) + \"\\n\")\n",
    "            \n",
    "    klass = 1\n",
    "    path = os.path.join(TRAIN_IMG_DIR,'cities')\n",
    "    for f in os.listdir(path):\n",
    "        filename = os.path.join(path, f)\n",
    "        myfile.write(filename + \",\" + str(klass) + \"\\n\")\n",
    "        \n",
    "    klass = 2\n",
    "    path = os.path.join(TRAIN_IMG_DIR,'mountains')\n",
    "    for f in os.listdir(path):\n",
    "        filename = os.path.join(path, f)\n",
    "        myfile.write(filename + \",\" + str(klass) + \"\\n\")\n",
    "        \n",
    "\n",
    "# Test Data\n",
    "with open(TEST_IMG_LABELS, \"w\") as myfile:\n",
    "    klass = 0\n",
    "    path = os.path.join(TEST_IMG_DIR,'farms')\n",
    "    for f in os.listdir(path):\n",
    "        filename = os.path.join(path, f)\n",
    "        myfile.write(filename + \",\" + str(klass) + \"\\n\")\n",
    "            \n",
    "    klass = 1\n",
    "    path = os.path.join(TEST_IMG_DIR,'cities')\n",
    "    for f in os.listdir(path):\n",
    "        filename = os.path.join(path, f)\n",
    "        myfile.write(filename + \",\" + str(klass) + \"\\n\")\n",
    "        \n",
    "    klass = 2\n",
    "    path = os.path.join(TEST_IMG_DIR,'mountains')\n",
    "    for f in os.listdir(path):\n",
    "        filename = os.path.join(path, f)\n",
    "        myfile.write(filename + \",\" + str(klass) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "Now that we have downloaded all of our imagery, we can design, train, and evaluate a simple convolutional neural network to classify them.\n",
    "\n",
    "This section will assume that you know the general vocabulary of neural networks and statistics, but not TensorFlow. The math underpining neural networks is an entire field in itself and can't be covered here. If you're interested in learning the science, Stanford makes its excellent CS231n available online for free: https://cs231n.github.io/. If that course is a bit too advance, Andrew Ng's Machine Learning course on Coursera is a very good introduction to Machine Learning in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Model\n",
    "#\n",
    "\n",
    "\n",
    "#\n",
    "# By convention, x is used to refer to the input to a statistical model\n",
    "# and y refers to the model's output. Since this is supervised learning\n",
    "# we must provide labels for the data. These labels can be thought of\n",
    "# as the \"correct answers.\" We will use y_ to describe these.\n",
    "#\n",
    "# Placeholders are variables in a TensorFlow model that a user must fill\n",
    "# before training or testing the model. (We will provided values for these\n",
    "# place hodlers later.)\n",
    "#\n",
    "# Keep in mind that TensorFlow works using a concept it calls 'defered execution.'\n",
    "# This means that as we call functions like tf.reshape() and tf.multiply(), no\n",
    "# computations are actually happening yet. Tensorflow records the operations and\n",
    "# connections we make in this section and executes them noly when we train and then test\n",
    "# the network later.\n",
    "#\n",
    "\n",
    "# Our input images will be a 50x50x3 image flattened into a vector\n",
    "x = tf.placeholder(tf.float32, [None, 50*50*3])\n",
    "# The answers will be given as a one-hot-array. This is an array where exactly one\n",
    "# element is 1 and the rest are zeros. For example: [0,1,0]\n",
    "y_ = tf.placeholder(tf.float32, [None, 3])\n",
    "# The training placeholder will allow us to turn on and off certain network features\n",
    "# like dropout and batch normalization\n",
    "training = tf.placeholder(tf.bool)\n",
    "\n",
    "\n",
    "input_norm = tf.contrib.layers.batch_norm(x, \n",
    "                                  center=True, scale=True, \n",
    "                                  is_training=training)\n",
    "\n",
    "\n",
    "# Since we are using a convolutional neural network we must convert the flattened image\n",
    "# into a proper image shape.\n",
    "input_layer = tf.reshape(input_norm, [-1, 50, 50, 3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Convolution and Pooling Layers\n",
    "#\n",
    "\n",
    "# Convolutional Layer #1\n",
    "conv1 = tf.layers.conv2d(\n",
    "    inputs=input_layer,\n",
    "    filters=32,\n",
    "    kernel_size=[3, 3],\n",
    "    padding=\"valid\",\n",
    "    activation=tf.nn.relu)\n",
    "\n",
    "# Pooling Layer #1\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "# pool1_norm = tf.contrib.layers.batch_norm(pool1, center=True, scale=True, activation=tf.nn.relu, is_training=training)\n",
    "\n",
    "# Convolutional Layer #2 and Pooling Layer #2\n",
    "conv2 = tf.layers.conv2d(\n",
    "    inputs=pool1,\n",
    "    filters=64,\n",
    "    kernel_size=[3, 3],\n",
    "    padding=\"valid\",\n",
    "    activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "# pool2_norm = tf.contrib.layers.batch_norm(pool2, center=True, scale=True, activation=tf.nn.relu, is_training=training)\n",
    "\n",
    "# Convolutional Layer #3 (no pooling)\n",
    "conv3 = tf.layers.conv2d(\n",
    "    inputs=pool2,\n",
    "    filters=64,\n",
    "    kernel_size=[3, 3],\n",
    "    padding=\"valid\",\n",
    "    activation=tf.nn.relu)\n",
    "# conv3_norm = tf.contrib.layers.batch_norm(conv3, center=True, scale=True, activation=tf.nn.relu, is_training=training)\n",
    "\n",
    "\n",
    "#\n",
    "# Fully Connected Layers\n",
    "#\n",
    "\n",
    "\n",
    "# Dense Layer\n",
    "conv3_flat = tf.reshape(conv3, [-1, 9 * 9 * 64])\n",
    "fc1 = tf.layers.dense(inputs=conv3_flat, units=1024, activation=tf.nn.relu)\n",
    "# fc1_norm = tf.contrib.layers.batch_norm(fc1, center=True, scale=True, activation=tf.nn.relu, is_training=training)\n",
    "dropout = tf.layers.dropout(\n",
    "    inputs=fc1,\n",
    "    rate=0.6,\n",
    "    training= True)\n",
    "\n",
    "# Model Output. We want this to be a one-hot array.\n",
    "y = tf.layers.dense(inputs=dropout, units=3)\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# The loss function, sometimes called a cost function, measures how good the network's\n",
    "# answer compares to the correct answer. A lower loss means a better answer.\n",
    "# A good loss function smoothly approaches zero as two answers approach each other.\n",
    "# 'Softmax' refers to the process of turing the y array, which could contain any values,\n",
    "# into a matrix where all the elements sum to 1. Since every image belongs only to one class,\n",
    "# this makes sense.\n",
    "# We will be using a common classifier loss function: the cross-entropy loss. It's not\n",
    "# too important to know how it works right now.\n",
    "#\n",
    "\n",
    "loss = None\n",
    "train_op = None\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(\n",
    "    onehot_labels=y_, # ground truth\n",
    "    logits=y) # network output\n",
    "\n",
    "#\n",
    "# Here we define an accuracy function so that we can have some\n",
    "# visibility into how well our model is learning. This is used during\n",
    "# the training step.\n",
    "#\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "model_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# We'll also calculate the softmax of the output for easier predictions\n",
    "y_softmax = tf.nn.softmax(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# It is common to train a neural network on \"batches\" of images. This creates\n",
    "# smoother gradients and expedites learning. To batch images we will stack 3-dimentional\n",
    "# images (width x height x channels) in the fourth dimention to create a 4-dimentional tensor\n",
    "# with the dimentions (batch_size x height x width x channels)\n",
    "#\n",
    "# We'll define a function to batch images for us, which we will use in the next section.\n",
    "#\n",
    "\n",
    "def gee_batch(data_label_file, batch_size):\n",
    "    \"\"\"\n",
    "    Generates image batches.\n",
    "    \n",
    "    data_label_file: File path of CSV file detailing filenames and labels\n",
    "    batch_size: Number of images to stack\n",
    "    \"\"\"\n",
    "    \n",
    "    # read CSV file\n",
    "    lines = open(data_label_file).read().splitlines()\n",
    "    \n",
    "    img_list = []\n",
    "    label_list = []\n",
    "    for i in range(batch_size):\n",
    "        # Choose a random image from the dataset\n",
    "        png_path, label = random.choice(lines).split(',')\n",
    "        # Load the image\n",
    "        img_list.append(misc.imread(png_path).flatten())\n",
    "        # And generate a one-hot array for the label\n",
    "        one_hot = np.zeros(3)\n",
    "        one_hot[int(label)] = 1\n",
    "        label_list.append(one_hot)\n",
    "        \n",
    "    return np.stack(img_list, axis=0), np.stack(label_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Training\n",
    "#\n",
    "# Now we'll train the network. All the operations we defined earlier will be\n",
    "# executed in this section. If you're using a CPU for calculations (which you\n",
    "# probably are) this section could take several hours, even for the few thousand\n",
    "# iterations. If you see loss flatten out, though, you can halt the kernel and\n",
    "# continue to to the next cell for evaluation.\n",
    "# (A note on GPUs: Tensorflow only support NVIDIA GPUs right now, so even if you\n",
    "# have a GPU you might not be able to use it. If you do have an NVIDIA GPU you'll\n",
    "# have to recompile Tensorflow with the CUDA drivers. That process won't be\n",
    "# covered here.)\n",
    "# \n",
    "\n",
    "\n",
    "# The 'optimizer' is the algorithm we will use to minimize the cost function.\n",
    "# This is a surprisingly complex issue with many approaches, although Adam\n",
    "# is a good default.\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) # Required for batch norm\n",
    "with tf.control_dependencies(update_ops): # Required for batch norm\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    starter_learning_rate = 1e-4\n",
    "    learning_rate = tf.train.exponential_decay(learning_rate = starter_learning_rate,\n",
    "                                               global_step = global_step,\n",
    "                                               decay_steps = 100,\n",
    "                                               decay_rate = 0.96,\n",
    "                                               staircase=True)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "\n",
    "# Initialize TensorFlow\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "# And run 20k iterations\n",
    "for i in range(12000):\n",
    "    # Load a batch of images\n",
    "    example_batch, label_batch = gee_batch(TRAIN_IMG_LABELS, 128)\n",
    "    \n",
    "    # Every 100 iterations we evaluate how well the network is performing. We're using\n",
    "    # the test set to display loss and accuracy; expect performance on the test\n",
    "    # set to be worse.\n",
    "    if i%100 == 0:\n",
    "        train_accuracy, loss_out, lr = sess.run( fetches = [model_accuracy, loss, learning_rate],\n",
    "                                       feed_dict={x : example_batch,\n",
    "                                                  y_: label_batch,\n",
    "                                                  training: False})\n",
    "        print \"Step\", i, \"Loss:\", loss_out, \"Accuracy:\", train_accuracy, \"LR:\", lr\n",
    "        \n",
    "    # run an iteration\n",
    "    optimizer.run(feed_dict={x:example_batch,\n",
    "                             y_: label_batch,\n",
    "                             training: True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Evaluation\n",
    "# \n",
    "# Now we will evaluate the performance of the network by measuring the accuracy on a batch of\n",
    "# images from the test set.\n",
    "#\n",
    "# I get about 52% accuracy, which is pretty poor (but better than random, which would be 33%.)\n",
    "# See if you can do better!\n",
    "#\n",
    "\n",
    "example_batch, label_batch = gee_batch(TEST_IMG_LABELS, 256)\n",
    "\n",
    "train_accuracy = sess.run( fetches = [model_accuracy],\n",
    "                                     feed_dict={x : example_batch,\n",
    "                                                y_: label_batch,\n",
    "                                                training: False})\n",
    "\n",
    "\n",
    "print \"Accuracy in the test set:\", train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Prediction\n",
    "#\n",
    "# Now we will use the model to predict the class of some images from the test set.\n",
    "# We'll keep the one-hot array encoding for the labels so that you can see the network's\n",
    "# output. Higher predicted values mean that the network is more confident that the image\n",
    "# belongs to that class.\n",
    "# As a reminder, the classes are:\n",
    "# farm:     0  one-hot: [1,0,0]\n",
    "# city:     1  one-hot: [0,1,0]\n",
    "# mountain: 2  one-hot: [0,0,1]\n",
    "#\n",
    "# You can keep rerunning this cell to test more images (CTRL-Enter runs the selected cell.)\n",
    "\n",
    "\n",
    "example_batch, label_batch = gee_batch(TEST_IMG_LABELS, 1)\n",
    "\n",
    "groundtruth, predicted = sess.run(   fetches = [y_, y_softmax],\n",
    "                                     feed_dict={x : example_batch,\n",
    "                                                y_: label_batch,\n",
    "                                                training: False})\n",
    "\n",
    "\n",
    "img = example_batch.reshape((50,50,3))\n",
    "plt.imshow(img); plt.show()\n",
    "\n",
    "print \"predictions:\", [ round(elem, 4) for elem in predicted[0] ]\n",
    "print \"ground truth:\", groundtruth[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
