{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment\n",
    "\n",
    "## All-in-one processor\n",
    "\n",
    "This file defines a neural network that processes several specrums at once. It does so by treating each spectrum the same as another image \"channel.\" In other words, it stacks the specrum layers and processes each example as a multi-channel image.\n",
    "\n",
    "In this experiment we are processing 5 different channels: Visual red, visual green, visual blue, altitude data, and night-time near-IR data (city lights). The data was collected and saved as a TFRecord previously in the Data Aquisition chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "# Math Stuff\n",
    "import scipy.misc, random, os\n",
    "import numpy as np\n",
    "\n",
    "# Google Earth Engine\n",
    "import ee\n",
    "from gee_library import *\n",
    "ee.Initialize()\n",
    "\n",
    "# debug stuff\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Threads\n",
    "import time, Queue\n",
    "from tqdm import trange\n",
    "from threading import Thread\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.protobuf.internal import api_implementation\n",
    "print(api_implementation._default_implementation_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR=\"data/experiment\"\n",
    "TEST_PROTO_FILENAME = os.path.join(DATA_DIR,\"multi_spectrum_test.tfrecords\")\n",
    "TRAIN_PROTO_FILENAME = os.path.join(DATA_DIR,\"multi_spectrum_train.tfrecords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "The `get_batch()` function reads from the TFRecord file we created before and extracts a batch of examples. So that we don't have to rewrite it for other experiments, it delivers each channel separatly. We will stack the channels later. \n",
    "\n",
    "This function is hard-coded for the spectrums used in this experiment to maximize readibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(proto_filename, batch_size):\n",
    "\n",
    "    NUMBER_OF_CLASSES=3\n",
    "    \n",
    "    filename_queue = tf.train.string_input_producer([proto_filename], num_epochs=None)\n",
    "    proto_reader = tf.TFRecordReader()\n",
    "\n",
    "    # get an example from file\n",
    "    _, serialized_example = proto_reader.read(filename_queue)\n",
    "\n",
    "    # unpack it\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            # We know the length of both fields. If not the\n",
    "            # tf.VarLenFeature could be used\n",
    "            'label': tf.FixedLenFeature([], tf.int64),\n",
    "            'R': tf.FixedLenFeature([50*50], tf.int64),\n",
    "            'G': tf.FixedLenFeature([50*50], tf.int64),\n",
    "            'B': tf.FixedLenFeature([50*50], tf.int64),\n",
    "            'elevation': tf.FixedLenFeature([50*50], tf.int64),\n",
    "            'nightlights': tf.FixedLenFeature([50*50], tf.int64),\n",
    "        })\n",
    "\n",
    "    # now we have the raw data, but we need to convert it to 32-bit floats so\n",
    "    # we can do some advance math on it.\n",
    "    R = tf.cast(features['R'], tf.float32)\n",
    "    G = tf.cast(features['G'], tf.float32)\n",
    "    B = tf.cast(features['B'], tf.float32)\n",
    "    elevation = tf.cast(features['elevation'], tf.float32)\n",
    "    nightlights = tf.cast(features['nightlights'], tf.float32)\n",
    "    \n",
    "    # The label is an integer; convert it to a one-hot array\n",
    "    label = tf.one_hot(features['label'], NUMBER_OF_CLASSES)\n",
    "\n",
    "    # and batch it\n",
    "    R_batch, G_batch, B_batch, elevation_batch, nightlight_batch, labels_batch = tf.train.shuffle_batch(\n",
    "        [R, G, B, elevation, nightlights, label],\n",
    "        batch_size=batch_size,\n",
    "        capacity=2000,\n",
    "        min_after_dequeue=1000)\n",
    "\n",
    "    return R_batch, G_batch, B_batch, elevation_batch, nightlight_batch, labels_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Definition\n",
    "\n",
    "Now we will define the all-in-one neural network. Remember, by \"all-in-one\" we mean that we stack the channels before feeding them into a single network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Required input placeholders\n",
    "#\n",
    "training = tf.placeholder(dtype=tf.bool, name=\"is_training\") # True if training, False if testing\n",
    "batch_size = tf.placeholder(dtype=tf.int32, name=\"batch_size\")\n",
    "\n",
    "\n",
    "#\n",
    "# Load the correct training/test data\n",
    "#\n",
    "\n",
    "# Define variables for both the traning and test batches. We will only use one of them per iteration, though.\n",
    "R_train_batch, G_train_batch, B_train_batch, elevation_train_batch, nightlight_train_batch, labels_train_batch = get_batch(TRAIN_PROTO_FILENAME, batch_size)\n",
    "R_test_batch, G_test_batch, B_test_batch, elevation_test_batch, nightlight_test_batch, labels_test_batch = get_batch(TRAIN_PROTO_FILENAME, batch_size)\n",
    "\n",
    "# Use a conditional tensor to select between using the test and training data\n",
    "R_batch, G_batch, B_batch, elevation_batch, nightlight_batch, labels_batch = tf.cond(training,\n",
    "                         lambda: (R_train_batch, G_train_batch, B_train_batch, elevation_train_batch, nightlight_train_batch, labels_train_batch), # training==True\n",
    "                         lambda: (R_test_batch,  G_test_batch,  B_test_batch,  elevation_test_batch,  nightlight_test_batch,  labels_test_batch)# training==False\n",
    "                        )\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Model\n",
    "#\n",
    "\n",
    "# Here's where we stack the channels to create a 50x50x5 pixel example batch.\n",
    "x = tf.stack(values=[R_batch, G_batch, B_batch, elevation_batch, nightlight_batch],\n",
    "             axis=2)\n",
    "y_ = labels_batch\n",
    "\n",
    "# Batch Normalization\n",
    "input_norm = tf.contrib.layers.batch_norm(x, \n",
    "                                  center=True, scale=True, \n",
    "                                  is_training=training)\n",
    "\n",
    "\n",
    "\n",
    "# Resize the data from 2500 element vectors to 2D images.\n",
    "input_layer = tf.reshape(input_norm, [-1, 50, 50, 5])\n",
    "\n",
    "\n",
    "#\n",
    "# Convolution and Pooling Layers\n",
    "#\n",
    "\n",
    "# Convolutional Layer #1\n",
    "conv1 = tf.layers.conv2d(\n",
    "    inputs=input_layer,\n",
    "    filters=32,\n",
    "    kernel_size=[3, 3],\n",
    "    padding=\"valid\",\n",
    "    activation=tf.nn.relu)\n",
    "\n",
    "# Pooling Layer #1\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "# pool1_norm = tf.contrib.layers.batch_norm(pool1, center=True, scale=True, activation=tf.nn.relu, is_training=training)\n",
    "\n",
    "# Convolutional Layer #2 and Pooling Layer #2\n",
    "conv2 = tf.layers.conv2d(\n",
    "    inputs=pool1,\n",
    "    filters=64,\n",
    "    kernel_size=[3, 3],\n",
    "    padding=\"valid\",\n",
    "    activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "# pool2_norm = tf.contrib.layers.batch_norm(pool2, center=True, scale=True, activation=tf.nn.relu, is_training=training)\n",
    "\n",
    "# Convolutional Layer #3 (no pooling)\n",
    "conv3 = tf.layers.conv2d(\n",
    "    inputs=pool2,\n",
    "    filters=64,\n",
    "    kernel_size=[3, 3],\n",
    "    padding=\"valid\",\n",
    "    activation=tf.nn.relu)\n",
    "# conv3_norm = tf.contrib.layers.batch_norm(conv3, center=True, scale=True, activation=tf.nn.relu, is_training=training)\n",
    "\n",
    "\n",
    "#\n",
    "# Fully Connected Layers\n",
    "#\n",
    "\n",
    "\n",
    "# Dense Layer\n",
    "conv3_flat = tf.reshape(conv3, [-1, 9 * 9 * 64])\n",
    "fc1 = tf.layers.dense(inputs=conv3_flat, units=1024, activation=tf.nn.relu)\n",
    "# fc1_norm = tf.contrib.layers.batch_norm(fc1, center=True, scale=True, activation=tf.nn.relu, is_training=training)\n",
    "dropout = tf.layers.dropout(\n",
    "    inputs=fc1,\n",
    "    rate=0.6,\n",
    "    training= True)\n",
    "\n",
    "# Model Output. This is the output of the last dense layer; it still has not\n",
    "# had the \"softmax\" applied to it since the softmax cross-entropy loss tensor\n",
    "# will handle that transformation. So the value of every element is something\n",
    "# between positive and negative infinity.\n",
    "y = tf.layers.dense(inputs=dropout, units=3)\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Loss\n",
    "#\n",
    "\n",
    "loss = None\n",
    "train_op = None\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(\n",
    "    onehot_labels=y_, # ground truth\n",
    "    logits=y) # network output\n",
    "\n",
    "\n",
    "#\n",
    "# Accuracy Output; helpful for observing performance\n",
    "# \n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "model_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Softmax output. This is what we will use for predictions.\n",
    "y_softmax = tf.nn.softmax(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Before we get started, let's make sure our network is loading the images correctly.\n",
    "#\n",
    "\n",
    "\n",
    "# Initialize tensorflow\n",
    "coord = tf.train.Coordinator()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# start the data reader tensors\n",
    "runner_threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "X, L = sess.run( fetches = [input_layer, labels_batch],\n",
    "                                 feed_dict={training: False, batch_size:1})\n",
    "R = X[0, :,:,0]\n",
    "G = X[0, :,:,1]\n",
    "B = X[0, :,:,2]\n",
    "E = X[0, :,:,3]\n",
    "N = X[0, :,:,4]\n",
    "\n",
    "print R.shape\n",
    "\n",
    "print \"Label:\", L\n",
    "plt.imshow(R, cmap='gray'); plt.show()\n",
    "plt.imshow(G, cmap='gray'); plt.show()\n",
    "plt.imshow(B, cmap='gray'); plt.show()\n",
    "plt.imshow(E, cmap='gray'); plt.show()\n",
    "plt.imshow(N, cmap='gray'); plt.show()\n",
    "\n",
    "\n",
    "# Gracefully shut down the neural network\n",
    "coord.request_stop()\n",
    "coord.join(runner_threads)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Train\n",
    "#\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) # Required for batch norm\n",
    "with tf.control_dependencies(update_ops): # Required for batch norm\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    starter_learning_rate = 1e-5\n",
    "    learning_rate = tf.train.exponential_decay(learning_rate = starter_learning_rate,\n",
    "                                               global_step = global_step,\n",
    "                                               decay_steps = 200,\n",
    "                                               decay_rate = 0.96,\n",
    "                                               staircase=True)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "\n",
    "# Initialize TensorFlow\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# start the data reader tensors\n",
    "tf.train.start_queue_runners(sess=sess)\n",
    "\n",
    "# And run 20k iterations\n",
    "for i in range(12000):\n",
    "    if i%100 == 0:\n",
    "        train_accuracy, loss_out, lr = sess.run( fetches = [model_accuracy, loss, learning_rate],\n",
    "                                                 feed_dict={training: False, batch_size:128})\n",
    "        print \"Step\", i, \"Loss:\", loss_out, \"Accuracy:\", train_accuracy, \"LR:\", lr\n",
    "        \n",
    "    # run an iteration\n",
    "    optimizer.run(feed_dict={batch_size:128,\n",
    "                             training: True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Evaluate\n",
    "#\n",
    "\n",
    "\n",
    "train_accuracy = sess.run( fetches = [model_accuracy],\n",
    "                           feed_dict={training: False, batch_size:128})\n",
    "\n",
    "\n",
    "print \"Accuracy in the test set:\", train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Prediction\n",
    "#\n",
    "# Remember, the classes are:\n",
    "# farm:     0  one-hot: [1,0,0]\n",
    "# city:     1  one-hot: [0,1,0]\n",
    "# mountain: 2  one-hot: [0,0,1]\n",
    "#\n",
    "# You can keep rerunning this cell to test more images (CTRL-Enter runs the selected cell.)\n",
    "\n",
    "\n",
    "\n",
    "X, L, Y = sess.run( fetches = [input_layer, labels_batch, y_softmax],\n",
    "                                 feed_dict={training: False, batch_size:1})\n",
    "R = X[0, :,:,0]\n",
    "G = X[0, :,:,1]\n",
    "B = X[0, :,:,2]\n",
    "E = X[0, :,:,3]\n",
    "N = X[0, :,:,4]\n",
    "\n",
    "\n",
    "# Since we are using more than 3 spectrums, it's not obvious how to visialize\n",
    "# our data. So we'll just show each spctrum individually as a grayscale 2D image.\n",
    "print \"Red Channel:\"\n",
    "plt.imshow(R, cmap='gray'); plt.show()\n",
    "print \"Green Channel:\"\n",
    "plt.imshow(G, cmap='gray'); plt.show()\n",
    "print \"Blue Channel:\"\n",
    "plt.imshow(B, cmap='gray'); plt.show()\n",
    "print \"Elevation Channel:\"\n",
    "plt.imshow(E, cmap='gray'); plt.show()\n",
    "print \"Night Light Channel:\"\n",
    "plt.imshow(N, cmap='gray'); plt.show()\n",
    "\n",
    "\n",
    "print \"Groundtruth label:\", L, \"Max:\", np.argmax(L)\n",
    "print \"Predicted label:\", Y, \"Max:\", np.argmax(Y)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
