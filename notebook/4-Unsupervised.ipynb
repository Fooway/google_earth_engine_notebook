{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "# Math Stuff\n",
    "import ee, scipy.misc, random, os\n",
    "import numpy as np\n",
    "from threading import Thread\n",
    "\n",
    "# debug stuff\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://indico.io/blog/tensorflow-data-inputs-part1-placeholders-protobufs-queues/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from scipy import misc\n",
    "\n",
    "def gee_batch(data_label_file, batch_size):\n",
    "    \"\"\"Generates batches of size `batch_size`\"\"\"\n",
    "    \n",
    "    # read file\n",
    "    lines = open(data_label_file).read().splitlines()\n",
    "    \n",
    "    img_list = []\n",
    "    label_list = []\n",
    "    for i in range(batch_size):\n",
    "        png_path, label = random.choice(lines).split(',')\n",
    "        \n",
    "        img = misc.imread(png_path)\n",
    "        processed_img = img[:,:,0]\n",
    "        small_img = scipy.misc.imresize(processed_img, (50,50))\n",
    "#         three_d_img = np.expand_dims(small_img, axis=2)\n",
    "        img_list.append(small_img.flatten() / 255.0)\n",
    "\n",
    "        one_hot = np.zeros(3)\n",
    "        one_hot[int(label)] = 1\n",
    "        label_list.append(one_hot)\n",
    "        \n",
    "    return np.stack(img_list, axis=0), np.stack(label_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create TFRecord\n",
    "#\n",
    "\n",
    "DATA_DIR=\"./ch3_data\"\n",
    "TRAIN_IMG_DIR=os.path.join(DATA_DIR, \"train_imgs\")\n",
    "TRAIN_IMG_LABELS=os.path.join(DATA_DIR, \"train.txt\")\n",
    "TEST_IMG_DIR=os.path.join(DATA_DIR, \"test_imgs\")\n",
    "TEST_IMG_LABELS=os.path.join(DATA_DIR, \"test.txt\")\n",
    "\n",
    "PROTO_FILENAME = \"gee_test.tfrecords\"\n",
    "\n",
    "# # Open a protobuffer writer\n",
    "# proto_writer = tf.python_io.TFRecordWriter(PROTO_FILENAME)\n",
    "\n",
    "# # Iterate over every exmaple and put it in the protobuffer\n",
    "# for line in open(TEST_IMG_LABELS).read().splitlines():\n",
    "#     png_path, label = line.split(',')\n",
    "#     img = misc.imread(png_path).flatten()\n",
    "    \n",
    "#     proto_example = tf.train.Example(\n",
    "#         features=tf.train.Features( # a map of string to Feature proto objects\n",
    "#             feature={\n",
    "#                 # A Feature contains one of either a int64_list,\n",
    "#                 # float_list, or bytes_list\n",
    "#                 'label': tf.train.Feature(\n",
    "#                     int64_list=tf.train.Int64List(value=[int(label)])),\n",
    "#                 'image': tf.train.Feature(\n",
    "#                     int64_list=tf.train.Int64List(value=img.astype(\"int64\")))\n",
    "#             }\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "#     # use the proto object to serialize the example to a string\n",
    "#     serialized = proto_example.SerializeToString()\n",
    "#     # write the serialized object to disk\n",
    "#     proto_writer.write(serialized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Look inside protobuff to make sure records are correctly recorded.\n",
    "#\n",
    "\n",
    "PROTO_FILENAME = \"gee_test.tfrecords\"\n",
    "\n",
    "i = 0\n",
    "for serialized_example in tf.python_io.tf_record_iterator(PROTO_FILENAME):\n",
    "    i = i + 1\n",
    "    if i > 3:\n",
    "        break\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(serialized_example)\n",
    "\n",
    "    # traverse the Example format to get data\n",
    "    image = example.features.feature['image'].int64_list.value\n",
    "    label = example.features.feature['label'].int64_list.value[0]\n",
    "    # do something\n",
    "    print label\n",
    "\n",
    "    img = np.array(image).astype(\"float32\")\n",
    "\n",
    "    plt.imshow(img.reshape((50,50, 3)), cmap='gray'); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Required input placeholders\n",
    "#\n",
    "training = tf.placeholder(dtype=tf.bool, name=\"is_training\") # True if training, False if testing\n",
    "batch_size = tf.placeholder(dtype=tf.int32, name=\"batch_size\")\n",
    "\n",
    "#\n",
    "# Our data-loading pipeline\n",
    "#\n",
    "\n",
    "def get_batch(proto_filename, batch_size):\n",
    "    filename_queue = tf.train.string_input_producer([proto_filename], num_epochs=None)\n",
    "    proto_reader = tf.TFRecordReader()\n",
    "\n",
    "    # Examples from the protobuf.\n",
    "    # TODO: what is the first returned value?\n",
    "    _, serialized_example = proto_reader.read(filename_queue)\n",
    "\n",
    "    # The serialized example is converted back to actual values\n",
    "    # by describing the format of the objects to be returned\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            # We know the length of both fields. If not the\n",
    "            # tf.VarLenFeature could be used\n",
    "            'label': tf.FixedLenFeature([], tf.int64),\n",
    "            'image': tf.FixedLenFeature([50*50*3], tf.int64)\n",
    "        })\n",
    "\n",
    "    # now we have the raw data\n",
    "    label = features['label']\n",
    "    image = features['image']\n",
    "\n",
    "    # wrest the data into the desired orientation\n",
    "    cast_img = tf.cast(image, tf.float32)\n",
    "    threeD_img = tf.reshape(cast_img, [50,50, 3])\n",
    "    bw_img = tf.slice(threeD_img, [0, 0, 0], [50, 50, 1])\n",
    "    oneD_img = tf.reshape(bw_img, [50*50])\n",
    "    squashed_img = tf.divide(oneD_img, 255)\n",
    "\n",
    "    # and batch it\n",
    "    images_batch, labels_batch = tf.train.shuffle_batch(\n",
    "        [squashed_img, label], batch_size=batch_size,\n",
    "        capacity=2000,\n",
    "        min_after_dequeue=1000)\n",
    "\n",
    "    return images_batch, labels_batch\n",
    "\n",
    "\n",
    "#\n",
    "# Load the correct training/test data\n",
    "#\n",
    "\n",
    "TRAIN_PROTO_FILENAME = \"gee_train_large.tfrecords\"\n",
    "TEST_PROTO_FILENAME = \"gee_test_large.tfrecords\"\n",
    "\n",
    "train_images_batch, train_labels_batch = get_batch(TRAIN_PROTO_FILENAME, batch_size)\n",
    "test_images_batch, test_labels_batch = get_batch(TEST_PROTO_FILENAME, batch_size)\n",
    "\n",
    "images_batch, labels_batch = tf.cond(training,\n",
    "                         lambda: (train_images_batch, train_labels_batch),\n",
    "                         lambda: (test_images_batch, test_labels_batch)\n",
    "                        )\n",
    "\n",
    "\n",
    "#\n",
    "# Model\n",
    "#\n",
    "\n",
    "\n",
    "x = images_batch\n",
    "y_ = images_batch\n",
    "\n",
    "\n",
    "# input_norm = tf.contrib.layers.batch_norm(x, \n",
    "#                                   center=True, scale=True, \n",
    "#                                   is_training=training)\n",
    "\n",
    "\n",
    "\n",
    "# Ensure our images are the correct shape\n",
    "input_layer = tf.reshape(x, [-1, 50, 50, 1])\n",
    "\n",
    "\n",
    "#\n",
    "# Convolutions\n",
    "#\n",
    "\n",
    "# Convolutional Layer #1\n",
    "conv1 = tf.layers.conv2d(\n",
    "    inputs=input_layer,\n",
    "    filters=16,\n",
    "    kernel_size=[3, 3],\n",
    "    strides = [1,1],\n",
    "    padding=\"valid\",\n",
    "    activation=tf.nn.relu)\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "# Convolutional Layer #2\n",
    "conv2 = tf.layers.conv2d(\n",
    "    inputs=pool1,\n",
    "    filters=16,\n",
    "    kernel_size=[3, 3],\n",
    "    strides = [1,1],\n",
    "    padding=\"valid\",\n",
    "    activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "# Convolutional Layer #3\n",
    "conv3 = tf.layers.conv2d(\n",
    "    inputs=pool2,\n",
    "    filters=16,\n",
    "    kernel_size=[4, 4],\n",
    "    strides = [1,1],\n",
    "    padding=\"valid\",\n",
    "    activation=tf.nn.relu)\n",
    "pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n",
    "\n",
    "# Dense Layer\n",
    "conv3_flat = tf.reshape(pool3, [-1, 4 * 4 * 16])\n",
    "fc1 = tf.layers.dense(inputs=conv3_flat, units=256, activation=tf.nn.relu)\n",
    "\n",
    "fc2 = tf.layers.dense(inputs=fc1, units=256, activation=tf.nn.relu)\n",
    "\n",
    "fc3 = tf.layers.dense(inputs=fc2, units=50*50, activation=tf.nn.relu)\n",
    "\n",
    "\n",
    "#\n",
    "# Loss\n",
    "#\n",
    "\n",
    "loss = None\n",
    "train_op = None\n",
    "y_pred = fc3\n",
    "y_true = y_\n",
    "\n",
    "loss = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\n",
    "\n",
    "# fc_activations = layerOutputs.append(fc2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Train\n",
    "#\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "starter_learning_rate = 1e-3\n",
    "learning_rate = tf.train.exponential_decay(learning_rate = starter_learning_rate,\n",
    "                                           global_step = global_step,\n",
    "                                           decay_steps = 200,\n",
    "                                           decay_rate = 0.96,\n",
    "                                           staircase=True)\n",
    "\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) # batch norm\n",
    "with tf.control_dependencies(update_ops): # batch norm\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "\n",
    "# Initialize tensorflow\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# start the data reader tensors\n",
    "tf.train.start_queue_runners(sess=sess)\n",
    "\n",
    "# And run 10k iterations\n",
    "for i in range(30000):\n",
    "    \n",
    "    # Debug output\n",
    "    if i%100 == 1:\n",
    "        prediction, loss_out = sess.run( fetches = [y_pred, loss],\n",
    "                                         feed_dict={training: False, batch_size:256})\n",
    "        print i, \":\", loss_out\n",
    "    \n",
    "    # run an iteration\n",
    "    optimizer.run(feed_dict={training: True, batch_size:256})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "\n",
    "# farm, city, mountain\n",
    "\n",
    "\n",
    "img_in, prediction, loss_out, feature_vector = sess.run( fetches = [y_true,y_pred, loss, fc2],\n",
    "                                         feed_dict={training: False, batch_size:1})\n",
    "\n",
    "img_in = img_in.reshape((50,50))\n",
    "prediction = prediction.reshape((50,50))\n",
    "\n",
    "silly_img = scipy.misc.imresize(scipy.misc.imresize(img_in, (16,16)), (50,50)) / 255.0\n",
    "diff_img = img_in - prediction\n",
    "\n",
    "\n",
    "print \"Prediction difference:\", np.mean(np.square(img_in - prediction))\n",
    "print \"Silly difference:     \", np.mean(np.square(img_in - silly_img))\n",
    "\n",
    "plt.imshow(img_in, cmap='gray', vmin=0, vmax=1); plt.show()\n",
    "plt.imshow(prediction, cmap='gray', vmin=0, vmax=1); plt.show()\n",
    "plt.imshow(silly_img, cmap='gray', vmin=0, vmax=1); plt.show()\n",
    "plt.hist(diff_img.flatten()); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Clustering\n",
    "#\n",
    "\n",
    "from pylab import plot,show\n",
    "from numpy import vstack,array\n",
    "from numpy.random import rand\n",
    "from scipy.cluster.vq import kmeans,vq\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def featurize_image():\n",
    "    img, feature_vector = sess.run( fetches = [y_true, fc2], feed_dict={training: False, batch_size:1})\n",
    "    return img, feature_vector\n",
    "\n",
    "\n",
    "#\n",
    "# Calculate Error\n",
    "#\n",
    "def cluster_error(data, centroids, idx):\n",
    "    sum_error = 0\n",
    "    for i in range(idx.shape[0]):\n",
    "        error = dst = distance.euclidean(data[i, :], centroids[idx[i], :])\n",
    "        sum_error += error\n",
    "    return sum_error\n",
    "        \n",
    "        \n",
    "#\n",
    "# Collect Data\n",
    "#\n",
    "data_img_list = []\n",
    "\n",
    "for i in range(500):\n",
    "    img, feature_vector = featurize_image()\n",
    "    sample = {\n",
    "        'img': img,\n",
    "        'feature_vector': feature_vector\n",
    "    }\n",
    "    data_img_list.append(sample)\n",
    "\n",
    "data = np.squeeze(np.array([d['feature_vector'] for d in data_img_list]))\n",
    "   \n",
    "\n",
    "\n",
    "# #\n",
    "# # Mean Shift\n",
    "# #\n",
    "# from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "\n",
    "# # The following bandwidth can be automatically detected using\n",
    "# bandwidth = estimate_bandwidth(data, quantile=0.2, n_samples=100)\n",
    "# print bandwidth\n",
    "    \n",
    "    \n",
    "# ms = MeanShift(bandwidth=0.5, bin_seeding=True)\n",
    "# ms.fit(data)\n",
    "# labels = ms.labels_\n",
    "# cluster_centers = ms.cluster_centers_\n",
    "\n",
    "# labels_unique = np.unique(labels)\n",
    "# n_clusters_ = len(labels_unique)\n",
    "\n",
    "# print(\"number of estimated clusters : %d\" % n_clusters_)\n",
    "\n",
    "\n",
    "    \n",
    "# #\n",
    "# # K Means\n",
    "# #\n",
    "\n",
    "# k_list = []\n",
    "# error_list = []\n",
    "\n",
    "# for k in range(2,20):\n",
    "#     centroids,_ = kmeans(data,k)\n",
    "#     # assign each sample to a cluster\n",
    "#     idx,_ = vq(data,centroids)\n",
    "\n",
    "#     error = cluster_error(data, centroids, idx)\n",
    "#     print \"k=\", k, \":\", error\n",
    "#     k_list.append(k)\n",
    "#     error_list.append(cluster_error(data, centroids, idx))\n",
    "    \n",
    "# plt.plot(k_list, error_list, '-o')\n",
    "# plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "K=5\n",
    "centroids,_ = kmeans(data,K)\n",
    "# assign each sample to a cluster\n",
    "idx,_ = vq(data,centroids)\n",
    "\n",
    "\n",
    "\n",
    "for k in range(K):\n",
    "    p = 1\n",
    "    print \"Cluster\", k\n",
    "    \n",
    "    # collect images in class\n",
    "    class_images = [data_img_list[i]\n",
    "                    for i in range(idx.shape[0])\n",
    "                    if idx[i] == k]\n",
    "    \n",
    "    # sort the image list based on each image's distance from the cluster center\n",
    "    class_images.sort(\n",
    "        key=lambda i_data: distance.euclidean(i_data['feature_vector'], centroids[k])\n",
    "    )\n",
    "    \n",
    "    for image_data in class_images:\n",
    "        if p <= 4*5:\n",
    "            plt.subplot(4, 5, p)\n",
    "            plt.axis('off')    \n",
    "            plt.imshow(image_data['img'].reshape((50,50)), cmap='gray')\n",
    "            p += 1\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
