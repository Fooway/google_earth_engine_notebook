{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multispectral processing Experiment\n",
    "\n",
    "## Data aquisition\n",
    "\n",
    "There is more than one way to deal with multispectral data. You can process each spectrum individually, arriving at a conclusion for each, and combine the conclusions in a post-processing step. You can also create an algorithm that has\n",
    "access to each spectrum and processes them all together. This experiment will compare the two approaches.\n",
    "\n",
    "This program downloads imagery from Google Earth Engine. It will save the imagery in a binary protobuf file in a way that will make it easy to access each spectrum individually later. This way, we can use the same data for each experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protobuf implementation: python\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "# Math Stuff\n",
    "import scipy.misc, random, os\n",
    "import numpy as np\n",
    "\n",
    "# Google Earth Engine\n",
    "import ee\n",
    "from gee_library import *\n",
    "ee.Initialize()\n",
    "\n",
    "# debug stuff\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Threads\n",
    "import time, Queue\n",
    "from tqdm import trange\n",
    "from threading import Thread\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# The python protobuf libraries can be implemented in C++ or Python. They\n",
    "# both work the same, although the Python implementation can be a bit slow. This line\n",
    "# lets you know which implementation is being used (the Docker image\n",
    "# should be using the 'cpp' implementation.)\n",
    "from google.protobuf.internal import api_implementation\n",
    "print \"Protobuf implementation:\", api_implementation._default_implementation_type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "DATA_DIR=\"data/experiment\"\n",
    "TEST_PROTO_FILENAME = os.path.join(DATA_DIR,\"multi_spectrum_test.tfrecords\")\n",
    "TEST_EXAMPLES_PER_CLASS=300\n",
    "\n",
    "TRAINING_PROTO_FILENAME = os.path.join(DATA_DIR,\"multi_spectrum_train.tfrecords\")\n",
    "TRAINING_EXAMPLES_PER_CLASS=1000\n",
    "\n",
    "METERS = 600 # Each image patch will cover a 600x600 meter section of earth\n",
    "PIXELS = 50 # each image patch will measure 50x50 pixels\n",
    "\n",
    "# Create the data directory if necessary\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "\n",
    "#\n",
    "# Just like before, we will define geographic areas to select imagery from.\n",
    "#\n",
    "\n",
    "# Cities\n",
    "brooklyn= ((-73.965471, 40.614974), (-73.920207, 40.693991))\n",
    "longisland= ((-73.918610, 40.713007), (-73.840551, 40.775980))\n",
    "queens= ((-73.821792, 40.749724), (-73.760813, 40.780303))\n",
    "sf1= ((-122.453085, 37.719024), (-122.394265, 37.789567))\n",
    "sanjose= ((-122.033408, 37.243222), (-121.832452, 37.414198))\n",
    "sandiego= ((-117.144966, 32.743224), (-117.098079, 32.761772))\n",
    "sandiego2= ((-117.098079, 32.690284), (-117.021168, 32.743224))\n",
    "denver= ((-105.127158, 39.569603), (-104.890206, 39.825191))\n",
    "neworleans= ((-90.229627, 29.967342), (-90.034561, 30.016651))\n",
    "baltimore= ((-76.651899, 39.287861), (-76.609940, 39.311176))\n",
    "# Farmland\n",
    "kentucky= ((-84.479444, 38.110622), (-84.335569, 38.258371))\n",
    "kansas= ((-97.533941, 38.105647), (-96.815051, 38.366043))\n",
    "montana= ((-108.994821, 45.875502), (-108.770538, 46.105918))\n",
    "california= ((-121.789047, 38.223409), (-121.575699, 38.473852))\n",
    "virginia= ((-76.838359, 36.483186), (-76.609497, 36.684365))\n",
    "# Mountains\n",
    "cascades = ((-121.575448, 48.224966), (-120.395554, 48.955637))\n",
    "sierranevadas = ((-120.479266, 38.206113), (-120.198767, 39.346931))\n",
    "yellowstone = ((-110.042831, 43.716602), (-109.379713, 44.437358))\n",
    "rockies = ((-106.790375, 38.610576), (-106.352140, 39.315902))\n",
    "rockies2 = ((-107.872873, 37.627164), (-106.433726, 38.047526))\n",
    "yosemite = ((-119.956063, 37.535445), (-119.282902, 38.176927))\n",
    "\n",
    "\n",
    "training_cities = [brooklyn, longisland, queens, sf1, sanjose, sandiego, sandiego2]\n",
    "test_cities = [baltimore, neworleans]\n",
    "\n",
    "training_mountains = [cascades, sierranevadas, yellowstone, rockies]\n",
    "test_mountains=[yosemite, rockies2]\n",
    "\n",
    "training_farms=[montana, kansas, kentucky]\n",
    "test_farms=[virginia, california]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-threaded download pipeline\n",
    "\n",
    "Since our multispectral data will have more than 3 channels, traditional image formats will not be the best choices for storing our data. While previous chapters have included multi-threaded imagery downloaders, they saved their data to the file system as flat files, a thread-safe operation. This time we will be saving our data directly to the protobuf file. Since the tf.python_io.TFRecordWriter is not explicitly documented as thread-safe, we will run it in its own thread. This means that the \"downloader\" threads have to communicate with the \"writer\" thread. Luckily Python included thread-safe queues that we can use for message passing. \"Downloader\" threads will add their data to `img_queue` and  the \"writer\" thread consumes the data and writes it to disk.\n",
    "\n",
    "There are a few approaches to selecting and downloading different bands. We could have made the functions more general and \"smart,\" automatically resizing the protobuf features to fit different numbers of bands. Instead I chose to hard-code the bands and feature sizes, which is easier to read. While it takes more work to change, the explicit dimention definitions will throw errors instead of silently \"fixing\" the network and possibly resulting in difficult-to-find silent errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Each element of img_queue will be a dictionary in the form {'band': numpy_array}\n",
    "img_queue = Queue.Queue()\n",
    "\n",
    "\n",
    "def get_RGB_tiles(resolution, tile_bounds):\n",
    "    geCollection=ee.ImageCollection('USDA/NAIP/DOQQ')\n",
    "    bands = ['R', 'G', 'B']\n",
    "    img_dict = img_at_region(geCollection, resolution, bands, tile_bounds)\n",
    "    return img_dict['R'], img_dict['G'], img_dict['B']\n",
    "\n",
    "def get_elevation_tiles(resolution, tile_bounds):\n",
    "    elevation_image = ee.Image('USGS/NED')\n",
    "    geCollection = ee.ImageCollection(elevation_image)\n",
    "    bands=['elevation']\n",
    "    img_dict = img_at_region(geCollection, resolution, bands, tile_bounds)\n",
    "    return img_dict['elevation']\n",
    "\n",
    "def get_nightlight_tiles(resolution, tile_bounds):\n",
    "    geCollection=ee.ImageCollection('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS')\n",
    "    bands=['stable_lights']\n",
    "    img_dict = img_at_region(geCollection, resolution, bands, tile_bounds)\n",
    "#     plt.imshow(np.array(img_dict['stable_lights']), cmap='gray', vmin=0, vmax=1); plt.show()\n",
    "    \n",
    "    return img_dict['stable_lights']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Download worker\n",
    "#\n",
    "def imagery_getter(label, meters, pixels, coords):\n",
    "    \"\"\"\n",
    "    Downloader thread. Downloads imagery, decodes into numpy data, and adds the matrix data to img_queue.\n",
    "    \n",
    "    geCollection: ee.ImageCollection object\n",
    "    meters: Each image will depict and area measuring meters x meters \n",
    "    pixels: Each image will measure pixels x pixels\n",
    "    coords: Two gps points describing a rectangle in the form:\n",
    "    ((longitude_min, latitude_min),(longitude_max, latitude_max))\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get random location in box\n",
    "        ((longmin, latmin),(longmax, latmax)) = coords\n",
    "\n",
    "        # get random coords\n",
    "        longitude = random.uniform(longmin, longmax)\n",
    "        latitude = random.uniform(latmin, latmax)\n",
    "\n",
    "        # Calculate resolution\n",
    "        resolution = meters/pixels\n",
    "\n",
    "        # Build the GPS box Geometry object\n",
    "        tile_bounds = square_centered_at(\n",
    "            point = (longitude, latitude),\n",
    "            half_distance = meters / 2\n",
    "        )\n",
    "\n",
    "        # request imagery\n",
    "        R,G,B, = get_RGB_tiles(resolution, tile_bounds)\n",
    "        elevation = get_elevation_tiles(resolution, tile_bounds)\n",
    "        nightlights = get_nightlight_tiles(resolution, tile_bounds)\n",
    "\n",
    "        # Add tiles to queue for writing\n",
    "        imagery_item = {'label': label,\n",
    "                        'R': scipy.misc.imresize(R, (pixels, pixels)),\n",
    "                        'G': scipy.misc.imresize(G, (pixels, pixels)),\n",
    "                        'B': scipy.misc.imresize(B, (pixels, pixels)),\n",
    "                        'elevation': scipy.misc.imresize(elevation, (pixels, pixels)),\n",
    "                        'nightlights': scipy.misc.imresize(nightlights, (pixels, pixels))}\n",
    "        img_queue.put(imagery_item)\n",
    "        \n",
    "    # Error Handling\n",
    "    except ServerError as e:\n",
    "        print e, coords\n",
    "    except Exception as e:\n",
    "        print e, coords\n",
    "    return\n",
    "    \n",
    "\n",
    "#\n",
    "# Protobuf creator worker\n",
    "#\n",
    "def proto_writer_worker(PROTO_FILENAME):\n",
    "    \"\"\"\n",
    "    Writer thread. This function consumes data from img_queue and writes it to disk in the TFRecordWriter\n",
    "    binary format.\n",
    "    \n",
    "    PROTO_FILENAME: Filename of the binary TFRecordWriter file.\n",
    "    \"\"\"\n",
    "    \n",
    "    print \"Started protobuf writer.\"\n",
    "\n",
    "    # Open a protobuffer writer\n",
    "    proto_writer = tf.python_io.TFRecordWriter(PROTO_FILENAME)\n",
    "\n",
    "\n",
    "    # Consume things from the queue.\n",
    "    try: \n",
    "        while True:\n",
    "            \n",
    "            # Consume one item from the queue. Raise exception if empty for 60 seconds\n",
    "            example = img_queue.get(block=True, timeout=60)\n",
    "            \n",
    "            R = example['R'].flatten()\n",
    "            G = example['G'].flatten()\n",
    "            B = example['B'].flatten()\n",
    "            elevation = example['elevation'].flatten()\n",
    "            nightlights = example['nightlights'].flatten()\n",
    "            label=example['label']\n",
    "\n",
    "            proto_example = tf.train.Example(\n",
    "                features=tf.train.Features( # a map of string to Feature proto objects\n",
    "                    feature={\n",
    "                        # A Feature contains one of either a int64_list,\n",
    "                        # float_list, or bytes_list\n",
    "                        'label':       tf.train.Feature(int64_list=tf.train.Int64List(value=[int(label)])),\n",
    "                        'R':           tf.train.Feature(int64_list=tf.train.Int64List(value=R.astype(\"int64\"))),\n",
    "                        'G':           tf.train.Feature(int64_list=tf.train.Int64List(value=G.astype(\"int64\"))),\n",
    "                        'B':           tf.train.Feature(int64_list=tf.train.Int64List(value=B.astype(\"int64\"))),\n",
    "                        'elevation':   tf.train.Feature(int64_list=tf.train.Int64List(value=elevation.astype(\"int64\"))),\n",
    "                        'nightlights': tf.train.Feature(int64_list=tf.train.Int64List(value=nightlights.astype(\"int64\"))),\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # use the proto object to serialize the example to a string\n",
    "            serialized = proto_example.SerializeToString()\n",
    "            # write the serialized object to disk\n",
    "            proto_writer.write(serialized)\n",
    "            \n",
    "    except Queue.Empty:\n",
    "        print \"Queue empty. Protobuf worker stopped.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started protobuf writer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1000 [00:40<1:06:09,  4.01s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4d04f0ea0dfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mthreads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Cities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queue empty. Protobuf worker stopped.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Download TRAINING data\n",
    "#\n",
    "\n",
    "# When spawning threads, the main program will continue to run while the threads run in the background.\n",
    "# If we want to ever wait for all threads to complete before continuing with the main program\n",
    "# we have to keep track of all the threads we spawn, and call .join() on each of them. This\n",
    "# list is where we will keep track of them.\n",
    "threads = []\n",
    "\n",
    "#\n",
    "# Start writer worker\n",
    "#\n",
    "t = Thread(target=proto_writer_worker, args=[TRAINING_PROTO_FILENAME])\n",
    "t.start()\n",
    "threads.append(t)\n",
    "\n",
    "\n",
    "#\n",
    "# Start downloader workers\n",
    "#\n",
    "\n",
    "# Farms\n",
    "label = 0\n",
    "coord_list = training_farms\n",
    "\n",
    "for i in trange(TRAINING_EXAMPLES_PER_CLASS):\n",
    "    t = Thread(target=imagery_getter,\n",
    "               args=(label, METERS, PIXELS, random.choice(coord_list)))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "    time.sleep(4)\n",
    "    \n",
    "# Cities\n",
    "label = 1\n",
    "coord_list = training_cities\n",
    "\n",
    "for i in trange(TRAINING_EXAMPLES_PER_CLASS):\n",
    "    t = Thread(target=imagery_getter,\n",
    "               args=(label, METERS, PIXELS, random.choice(coord_list)))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "    time.sleep(4)\n",
    "               \n",
    "# Mountains\n",
    "label = 2\n",
    "coord_list = training_mountains\n",
    "\n",
    "for i in trange(TRAINING_EXAMPLES_PER_CLASS):\n",
    "    t = Thread(target=imagery_getter,\n",
    "               args=(label, METERS, PIXELS, random.choice(coord_list)))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "    time.sleep(4)\n",
    "\n",
    "# wait for all threads to finish\n",
    "for t in threads:\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Download TEST data\n",
    "#\n",
    "\n",
    "threads = []\n",
    "\n",
    "#\n",
    "# Start writer worker\n",
    "#\n",
    "t = Thread(target=proto_writer_worker, args=[TEST_PROTO_FILENAME])\n",
    "t.start()\n",
    "threads.append(t)\n",
    "\n",
    "\n",
    "#\n",
    "# Start downloader workers\n",
    "#\n",
    "\n",
    "# Farms\n",
    "label = 0\n",
    "coord_list = test_farms\n",
    "\n",
    "for i in trange(TEST_EXAMPLES_PER_CLASS):\n",
    "    t = Thread(target=imagery_getter,\n",
    "               args=(label, METERS, PIXELS, random.choice(coord_list)))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "    time.sleep(4)\n",
    "    \n",
    "# Cities\n",
    "label = 1\n",
    "coord_list = test_cities\n",
    "\n",
    "for i in trange(TEST_EXAMPLES_PER_CLASS):\n",
    "    t = Thread(target=imagery_getter,\n",
    "               args=(label, METERS, PIXELS, random.choice(coord_list)))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "    time.sleep(4)\n",
    "               \n",
    "# Mountains\n",
    "label = 2\n",
    "coord_list = test_mountains\n",
    "\n",
    "for i in trange(TEST_EXAMPLES_PER_CLASS):\n",
    "    t = Thread(target=imagery_getter,\n",
    "               args=(label, METERS, PIXELS, random.choice(coord_list)))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "    time.sleep(4)\n",
    "\n",
    "# wait for all threads to finish\n",
    "for t in threads:\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Just to get a warm fuzzy that the data was recorded correctly, let's look inside\n",
    "# the protobuff and plot some images.\n",
    "#\n",
    "\n",
    "i = 0\n",
    "for serialized_example in tf.python_io.tf_record_iterator(PROTO_FILENAME):\n",
    "    i = i + 1\n",
    "    if i > 1:\n",
    "        break\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(serialized_example)\n",
    "\n",
    "    # traverse the Example format to get data\n",
    "    R = example.features.feature['R'].int64_list.value\n",
    "    G = example.features.feature['G'].int64_list.value\n",
    "    B = example.features.feature['B'].int64_list.value\n",
    "    elevation = example.features.feature['elevation'].int64_list.value\n",
    "    nightlights = example.features.feature['nightlights'].int64_list.value\n",
    "    label = example.features.feature['label'].int64_list.value[0]\n",
    "    print label\n",
    "\n",
    "    plt.imshow(np.array(R).astype(\"float32\").reshape((50,50))); plt.show()\n",
    "    plt.imshow(np.array(G).astype(\"float32\").reshape((50,50))); plt.show()    \n",
    "    plt.imshow(np.array(B).astype(\"float32\").reshape((50,50))); plt.show()    \n",
    "    plt.imshow(np.array(elevation).astype(\"float32\").reshape((50,50))); plt.show()    \n",
    "    plt.imshow(np.array(nightlights).astype(\"float32\").reshape((50,50))); plt.show()        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
