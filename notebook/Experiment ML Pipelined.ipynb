{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment\n",
    "\n",
    "## Pipelined processor\n",
    "\n",
    "This file defines a neural network that processes several specrums individually. For each example, individual channels are sent through their own neural network. To use this system for classification, the output of all the neural networks must be combined with a post-processor. \n",
    "\n",
    "In this experiment we are processing 5 different channels: Visual red, visual green, visual blue, altitude data, and night-time near-IR data (city lights). The data was collected and saved as a TFRecord previously in the Data Aquisition chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "# Math Stuff\n",
    "import scipy.misc, random, os\n",
    "import numpy as np\n",
    "\n",
    "# Google Earth Engine\n",
    "import ee\n",
    "from gee_library import *\n",
    "ee.Initialize()\n",
    "\n",
    "# debug stuff\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Threads\n",
    "import time, Queue\n",
    "from tqdm import trange\n",
    "from threading import Thread\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.protobuf.internal import api_implementation\n",
    "print(api_implementation._default_implementation_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR=\"data/experiment\"\n",
    "TEST_PROTO_FILENAME = os.path.join(DATA_DIR,\"multi_spectrum_test.tfrecords\")\n",
    "TRAIN_PROTO_FILENAME = os.path.join(DATA_DIR,\"multi_spectrum_train.tfrecords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "The `get_batch()` function reads from the TFRecord file we created before and extracts a batch of examples. It delivers each channel separatly.\n",
    "\n",
    "This function is hard-coded for the spectrums used in this experiment to maximize readibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(proto_filename, batch_size):\n",
    "\n",
    "    NUMBER_OF_CLASSES=3\n",
    "    \n",
    "    filename_queue = tf.train.string_input_producer([proto_filename], num_epochs=None)\n",
    "    proto_reader = tf.TFRecordReader()\n",
    "\n",
    "    # get an example from file\n",
    "    _, serialized_example = proto_reader.read(filename_queue)\n",
    "\n",
    "    # unpack it\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            # We know the length of both fields. If not the\n",
    "            # tf.VarLenFeature could be used\n",
    "            'label': tf.FixedLenFeature([], tf.int64),\n",
    "            'R': tf.FixedLenFeature([50*50], tf.int64),\n",
    "            'G': tf.FixedLenFeature([50*50], tf.int64),\n",
    "            'B': tf.FixedLenFeature([50*50], tf.int64),\n",
    "            'elevation': tf.FixedLenFeature([50*50], tf.int64),\n",
    "            'nightlights': tf.FixedLenFeature([50*50], tf.int64),\n",
    "        })\n",
    "\n",
    "    # now we have the raw data, but we need to convert it to 32-bit floats so\n",
    "    # we can do some advance math on it.\n",
    "    R = tf.cast(features['R'], tf.float32)\n",
    "    G = tf.cast(features['G'], tf.float32)\n",
    "    B = tf.cast(features['B'], tf.float32)\n",
    "    elevation = tf.cast(features['elevation'], tf.float32)\n",
    "    nightlights = tf.cast(features['nightlights'], tf.float32)\n",
    "    \n",
    "    # The label is an integer; convert it to a one-hot array\n",
    "    label = tf.one_hot(features['label'], NUMBER_OF_CLASSES)\n",
    "\n",
    "    # and batch it\n",
    "    R_batch, G_batch, B_batch, elevation_batch, nightlight_batch, labels_batch = tf.train.shuffle_batch(\n",
    "        [R, G, B, elevation, nightlights, label],\n",
    "        batch_size=batch_size,\n",
    "        capacity=2000,\n",
    "        min_after_dequeue=1000)\n",
    "\n",
    "    return R_batch, G_batch, B_batch, elevation_batch, nightlight_batch, labels_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Definition\n",
    "\n",
    "Now we will define the pipelined neural network. For simplicity, this example will use identical networks for each channel. Instead of writing out the network definition 5 times, though, we will define a function that takes data as input and returns the network output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Required input placeholders\n",
    "#\n",
    "training = tf.placeholder(dtype=tf.bool, name=\"is_training\") # True if training, False if testing\n",
    "batch_size = tf.placeholder(dtype=tf.int32, name=\"batch_size\")\n",
    "\n",
    "\n",
    "##############\n",
    "# Data Input #\n",
    "##############\n",
    "\n",
    "# Define variables for both the traning and test batches. We will only use one of them per iteration, though.\n",
    "R_train_batch, G_train_batch, B_train_batch, elevation_train_batch, nightlight_train_batch, labels_train_batch = get_batch(TRAIN_PROTO_FILENAME, batch_size)\n",
    "R_test_batch, G_test_batch, B_test_batch, elevation_test_batch, nightlight_test_batch, labels_test_batch = get_batch(TRAIN_PROTO_FILENAME, batch_size)\n",
    "\n",
    "# Use a conditional tensor to select between using the test and training data\n",
    "R_batch, G_batch, B_batch, elevation_batch, nightlight_batch, labels_batch = tf.cond(training,\n",
    "                         lambda: (R_train_batch, G_train_batch, B_train_batch, elevation_train_batch, nightlight_train_batch, labels_train_batch), # training==True\n",
    "                         lambda: (R_test_batch,  G_test_batch,  B_test_batch,  elevation_test_batch,  nightlight_test_batch,  labels_test_batch)# training==False\n",
    "                        )\n",
    "\n",
    "\n",
    "\n",
    "####################\n",
    "# Model Definition #\n",
    "####################\n",
    "\n",
    "def pipelined_model(x, y_):\n",
    "\n",
    "    # Batch Normalization\n",
    "    input_norm = tf.contrib.layers.batch_norm(x, \n",
    "                                      center=True, scale=True, \n",
    "                                      is_training=training)\n",
    "\n",
    "\n",
    "\n",
    "    # Resize the data from 2500 element vectors to 2D images.\n",
    "    input_layer = tf.reshape(input_norm, [-1, 50, 50, 1])\n",
    "\n",
    "\n",
    "    #\n",
    "    # Convolution and Pooling Layers\n",
    "    #\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=32,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"valid\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "    # pool1_norm = tf.contrib.layers.batch_norm(pool1, center=True, scale=True, activation=tf.nn.relu, is_training=training)\n",
    "\n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"valid\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    # pool2_norm = tf.contrib.layers.batch_norm(pool2, center=True, scale=True, activation=tf.nn.relu, is_training=training)\n",
    "\n",
    "    # Convolutional Layer #3 (no pooling)\n",
    "    conv3 = tf.layers.conv2d(\n",
    "        inputs=pool2,\n",
    "        filters=64,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"valid\",\n",
    "        activation=tf.nn.relu)\n",
    "    # conv3_norm = tf.contrib.layers.batch_norm(conv3, center=True, scale=True, activation=tf.nn.relu, is_training=training)\n",
    "\n",
    "\n",
    "    #\n",
    "    # Fully Connected Layers\n",
    "    #\n",
    "\n",
    "\n",
    "    # Dense Layer\n",
    "    conv3_flat = tf.reshape(conv3, [-1, 9 * 9 * 64])\n",
    "    fc1 = tf.layers.dense(inputs=conv3_flat, units=1024, activation=tf.nn.relu)\n",
    "    # fc1_norm = tf.contrib.layers.batch_norm(fc1, center=True, scale=True, activation=tf.nn.relu, is_training=training)\n",
    "    dropout = tf.layers.dropout(\n",
    "        inputs=fc1,\n",
    "        rate=0.6,\n",
    "        training= True)\n",
    "\n",
    "    # Model Output. This is the output of the last dense layer; it still has not\n",
    "    # had the \"softmax\" applied to it since the softmax cross-entropy loss tensor\n",
    "    # will handle that transformation. So the value of every element is something\n",
    "    # between positive and negative infinity.\n",
    "    y = tf.layers.dense(inputs=dropout, units=3)\n",
    "\n",
    "\n",
    "\n",
    "    #\n",
    "    # Loss\n",
    "    #\n",
    "\n",
    "    loss = None\n",
    "    train_op = None\n",
    "\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels=y_, # ground truth\n",
    "        logits=y) # network output\n",
    "\n",
    "\n",
    "    #\n",
    "    # Accuracy Output; helpful for observing performance\n",
    "    # \n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    model_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    return y, loss, model_accuracy\n",
    "    \n",
    "    \n",
    "    \n",
    "#\n",
    "# Now that we have defined the model as a function, we will feed\n",
    "# each layer into it individually.\n",
    "#\n",
    "\n",
    "    # Here's where we stack the channels to create a 50x50x5 pixel example batch.\n",
    "    x = tf.stack(values=[R_batch, G_batch, B_batch, elevation_batch, nightlight_batch],\n",
    "                 axis=2)\n",
    "    y_ = labels_batch\n",
    "\n",
    "\n",
    "    \n",
    "R_logits, R_loss, R_accuracy = pipelined_model(R_batch, labels_batch)\n",
    "G_logits, G_loss, G_accuracy = pipelined_model(G_batch, labels_batch)\n",
    "B_logits, B_loss, B_accuracy = pipelined_model(B_batch, labels_batch)\n",
    "E_logits, E_loss, E_accuracy = pipelined_model(elevation_batch, labels_batch)\n",
    "N_logits, N_loss, N_accuracy = pipelined_model(nightlight_batch, labels_batch)\n",
    "\n",
    "# Softmax output. These tensors are what we will use for predictions.\n",
    "\n",
    "R_y = tf.nn.softmax(R_logits)\n",
    "G_y = tf.nn.softmax(G_logits)\n",
    "B_y = tf.nn.softmax(B_logits)\n",
    "E_y = tf.nn.softmax(E_logits)\n",
    "N_y = tf.nn.softmax(N_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Train\n",
    "#\n",
    "\n",
    "# Since we have 5 different pipelines, each processing different channels, we\n",
    "# could process each individually, one after another. However, we can define\n",
    "# an \"overall\" loss to minimize so that Tensorflow trains all 5 networks simultaneously.\n",
    "# (If this is confusing, just know that tf.train.AdamOptimizer.minimize will adjust the\n",
    "# weights of the network to minimize any variable. We *could* try to minimize R_loss,\n",
    "# and then try to minimize G_loss, and then try to minimize B_loss etc. What I've done\n",
    "# here is average all the losses together and asked tf.train.AdamOptimizer.minimize to\n",
    "# minimize their average. The result is that it will try to minimize all the losses so that\n",
    "# their average goes down.)\n",
    "overall_loss = R_loss + G_loss + B_loss + E_loss + N_loss\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) # Required for batch norm\n",
    "with tf.control_dependencies(update_ops): # Required for batch norm\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    starter_learning_rate = 1e-5\n",
    "    learning_rate = tf.train.exponential_decay(learning_rate = starter_learning_rate,\n",
    "                                               global_step = global_step,\n",
    "                                               decay_steps = 200,\n",
    "                                               decay_rate = 0.96,\n",
    "                                               staircase=True)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(overall_loss, global_step=global_step)\n",
    "\n",
    "\n",
    "# Initialize TensorFlow\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# start the data reader tensors\n",
    "tf.train.start_queue_runners(sess=sess)\n",
    "\n",
    "# And run 20k iterations\n",
    "for i in range(12000):\n",
    "    if i%100 == 0:\n",
    "        (loss_out,\n",
    "        R_loss_out, G_loss_out, B_loss_out,\n",
    "        E_loss_out, N_loss_out,\n",
    "        R_accuracy_out, G_accuracy_out, B_accuracy_out,\n",
    "        E_accuracy_out, N_accuracy_out) = sess.run( fetches = [overall_loss, R_loss, G_loss, B_loss, E_loss, N_loss,\n",
    "                                                              R_accuracy, G_accuracy, B_accuracy, E_accuracy, N_accuracy],\n",
    "                                                   feed_dict={training: False, batch_size:128})\n",
    "        print \"\"\n",
    "        print \"-- Step\", i, \"--\"\n",
    "        print \"- Loss Total:\", loss_out\n",
    "        print \"   R:\", R_loss_out, \"G:\", G_loss_out, \"B:\", B_loss_out, \"Elevation:\", E_loss_out, \"Nightlights:\", N_loss_out\n",
    "        print \"- Accuracy\"\n",
    "        print \"   R:\", R_accuracy_out, \"G:\", G_accuracy_out, \"B:\", B_accuracy_out, \"Elevation:\", E_accuracy_out, \"Nightlights:\", N_accuracy_out\n",
    "        \n",
    "        \n",
    "    # run an iteration\n",
    "    optimizer.run(feed_dict={batch_size:128,\n",
    "                             training: True})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation and Prediction\n",
    "\n",
    "This experiment pipelined the analysis of each spectrum. Each pipeline is able to classify an example image using only the spectrum it is designed for. In machine learning, each of these pipelines might be refered to as \"weak learners\" since they each learn different aspects of a dataset. In order to create a \"strong learner\" we must combine the classifications for each pipeline to create an overall classification. There are many ways to do this.\n",
    "\n",
    "The simplest way to combine weak learner classifications is to average the classifications of all the learners. A related way is to give each learner a vote and tally the results. A more sophisticated method would be to create another neural network that is given the outputs of each weak learner and some information about the input data. This last method could actually learn which classifier to trust more depending on what sort of image was given.\n",
    "\n",
    "But to keep it simple we will show the output of each weak learner, as well as the average of all the classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Evaluate\n",
    "#\n",
    "\n",
    "\n",
    "(R_accuracy_out,\n",
    " G_accuracy_out,\n",
    " B_accuracy_out,\n",
    " E_accuracy_out,\n",
    " N_accuracy_out) = sess.run( fetches = [R_accuracy,\n",
    "                                        G_accuracy,\n",
    "                                        B_accuracy,\n",
    "                                        E_accuracy,\n",
    "                                        N_accuracy],\n",
    "                             feed_dict={training: False, batch_size:128})\n",
    "print \"Accuracy in the test set:\"\n",
    "print \"   R:\", R_accuracy_out, \"G:\", G_accuracy_out, \"B:\", B_accuracy_out, \"Elevation:\", E_accuracy_out, \"Nightlights:\", N_accuracy_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Prediction\n",
    "#\n",
    "# Remember, the classes are:\n",
    "# farm:     0  one-hot: [1,0,0]\n",
    "# city:     1  one-hot: [0,1,0]\n",
    "# mountain: 2  one-hot: [0,0,1]\n",
    "#\n",
    "# You can keep rerunning this cell to test more images (CTRL-Enter runs the selected cell.)\n",
    "\n",
    "\n",
    "\n",
    "(R_batch_out,\n",
    " G_batch_out,\n",
    " B_batch_out,\n",
    " E_batch_out,\n",
    " N_batch_out,\n",
    " labels_out,\n",
    " R_y_out,\n",
    " G_y_out,\n",
    " B_y_out,\n",
    " E_y_out,\n",
    " N_y_out) = sess.run( fetches = [R_batch,\n",
    "                                 G_batch,\n",
    "                                 B_batch,\n",
    "                                 elevation_batch,\n",
    "                                 nightlight_batch,\n",
    "                                 labels_batch,\n",
    "                                 R_y,\n",
    "                                 G_y,\n",
    "                                 B_y,\n",
    "                                 E_y,\n",
    "                                 N_y],\n",
    "                      feed_dict={training: False, batch_size:1})\n",
    "\n",
    "print \"Red channel:\"\n",
    "plt.imshow(R_batch_out[0,:].reshape((50,50)), cmap='gray'); plt.show()\n",
    "print \"Green channel:\"\n",
    "plt.imshow(G_batch_out[0,:].reshape((50,50)), cmap='gray'); plt.show()\n",
    "print \"Blue channel:\"\n",
    "plt.imshow(B_batch_out[0,:].reshape((50,50)), cmap='gray'); plt.show()\n",
    "print \"Elevation channel:\"\n",
    "plt.imshow(E_batch_out[0,:].reshape((50,50)), cmap='gray'); plt.show()\n",
    "print \"Night Light channel:\"\n",
    "plt.imshow(N_batch_out[0,:].reshape((50,50)), cmap='gray'); plt.show()\n",
    "\n",
    "print \"Ground truth Label:\", labels_out, \"Max:\", np.argmax(labels_out)\n",
    "print \"Predicted labels:\"\n",
    "print \"R:\", R_y_out, \"Max:\", np.argmax(R_y_out)\n",
    "print \"G:\", G_y_out, \"Max:\", np.argmax(G_y_out)\n",
    "print \"B:\", B_y_out, \"Max:\", np.argmax(B_y_out)\n",
    "print \"E:\", E_y_out, \"Max:\", np.argmax(E_y_out)\n",
    "print \"N:\", N_y_out, \"Max:\", np.argmax(N_y_out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
